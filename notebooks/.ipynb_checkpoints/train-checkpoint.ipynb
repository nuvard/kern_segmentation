{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Using device: cuda\n",
      "True\n",
      "Tesla V100-PCIE-32GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "==> Preparing data\n",
      "==> Preparing model\n",
      "Using cache found in /headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "Using cache found in /headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "Adding attention\n",
      "==> Initialising sampler\n",
      "=====> Loading indices\n",
      "=====> Loading samples\n",
      "=====> Checking distribution\n",
      "=====> Assigning weights\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2565/2565 [08:50<00:00,  4.83it/s]\n",
      "==> Training model\n",
      "  0%|                                                    | 0/36 [00:09<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"../src/train.py\", line 382, in <module>\n",
      "    main()\n",
      "  File \"../src/train.py\", line 376, in main\n",
      "    train_loop(args)\n",
      "  File \"../src/train.py\", line 338, in train_loop\n",
      "    test_len = test(model, DEVICE, test_loader, loss, epoch, num_classes=NUM_CLASSES, wandb_log=WANDB)\n",
      "  File \"../src/train.py\", line 211, in test\n",
      "    output = model(data).cuda()\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/gen_efficientnet.py\", line 203, in forward\n",
      "    x = self.global_pool(x)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 92, in forward\n",
      "    input = module(input)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\", line 345, in forward\n",
      "    return self.conv2d_forward(input, self.weight)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\", line 342, in conv2d_forward\n",
      "    self.padding, self.dilation, self.groups)\n",
      "RuntimeError: Given groups=1, weight of size 6 588 1 1, expected input[36, 12, 5, 5] to have 588 channels, but got 12 channels instead\n"
     ]
    }
   ],
   "source": [
    "!python -W ignore ../src/train.py --tags \"3#drop0.2\" --base \"efficientnet_b0\" --image_size 128 --lr 1e-3 --epochs 200 \\\n",
    "--batch_size 36 --wandb 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-e7168d3a1b14>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-e7168d3a1b14>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    nn.BatchNorm3d(6),\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from attention_augmented_conv import AugmentedConv\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "                      AugmentedConv(in_channels=1280, out_channels=6, kernel_size=1, dk=40, dv=4, Nh=1, relative=False, stride=2)\n",
    "                     #nn.Conv2d(588, 6, kernel_size=1, padding = 1, stride=1, bias=False),\n",
    "                     torch.nn.BatchNorm3d(6), \n",
    "                     torch.nn.Dropout(p=0.25),\n",
    "                     torch.nn.AdaptiveAvgPool2d(1)\n",
    "                      ).to(\"cuda\")\n",
    "temp_input = torch.randn((16, 1280, 32, 32)).to('cuda')\n",
    "augmented_conv = AugmentedConv(in_channels=1280, out_channels=6, kernel_size=1, dk=40, dv=4, Nh=1, relative=False, stride=2).to('cuda')\n",
    "norm = torch.nn.BatchNorm2d(6).to(\"cuda\")\n",
    "\n",
    "conv_out = model(temp_input)\n",
    "print(conv_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Using device: cuda\n",
      "True\n",
      "Tesla V100-PCIE-32GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "wandb!\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.8.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in ../../../shared/kern_segmentation/logs/wandb/run-20191207_222740-rqsiwlo7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m1#drop0.2_mixnet_s_ft_0.001_6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/nuvard/kern\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/nuvard/kern/runs/rqsiwlo7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "==> Preparing data\n",
      "==> Preparing model\n",
      "Using cache found in /headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "Using cache found in /headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mixnet_s-a907afbc.pth\" to /headless/.cache/torch/checkpoints/mixnet_s-a907afbc.pth\n",
      "^C\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl-c pressed.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 255. Press ctrl-c to abort syncing.\n",
      "Traceback (most recent call last):\n",
      "  File \"../src/train.py\", line 382, in <module>\n",
      "    main()\n",
      "  File \"../src/train.py\", line 376, in main\n",
      "    train_loop(args)\n",
      "  File \"../src/train.py\", line 325, in train_loop\n",
      "    model, optimizer, loss = prepare_eff_model(lr=LR, device=DEVICE, name=BASE, inp_size = INP_SIZE, weight_decay=WD, beta_1=B1, beta_2=B2, im_size=IMAGE_SIZE)\n",
      "  File \"/headless/tmp/kd/src/model.py\", line 180, in prepare_eff_model\n",
      "    model =  torch.hub.load('rwightman/gen-efficientnet-pytorch', name, pretrained=True)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/hub.py\", line 359, in load\n",
      "    model = entry(*args, **kwargs)\n",
      "  File \"/headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/gen_efficientnet.py\", line 969, in mixnet_s\n",
      "    'mixnet_s', channel_multiplier=1.0, pretrained=pretrained, **kwargs)\n",
      "  File \"/headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/gen_efficientnet.py\", line 515, in _gen_mixnet_s\n",
      "    model = _create_model(model_kwargs, variant, pretrained)\n",
      "  File \"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 161556\n",
      "/headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/gen_efficientnet.py\", line 214, in _create_model\n",
      "    load_pretrained(model, model_urls[variant])\n",
      "  File \"/headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/helpers.py\", line 32, in load_pretrained\n",
      "    state_dict = load_state_dict_from_url(url, progress=False, map_location='cpu')\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/hub.py\", line 485, in load_state_dict_from_url\n",
      "    download_url_to_file(url, cached_file, hash_prefix, progress=progress)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/hub.py\", line 406, in download_url_to_file\n",
      "    buffer = u.read(8192)\n",
      "  File \"/headless/miniconda3/lib/python3.7/http/client.py\", line 457, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"/headless/miniconda3/lib/python3.7/http/client.py\", line 501, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"/headless/miniconda3/lib/python3.7/socket.py\", line 589, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/headless/miniconda3/lib/python3.7/ssl.py\", line 1071, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/headless/miniconda3/lib/python3.7/ssl.py\", line 929, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python -W ignore ../src/train.py --tags \"1#drop0.2\" --base \"mixnet_s\" --image_size 224 --wandb 1 \\\n",
    "          --batch_size 24 --inp_size 1536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -W ignore ../src/train.py --tags \"1#drop0.2#\" --base \"mnasnet_a1\" --image_size 224 --wandb 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
