{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ttach\n",
      "  Downloading https://files.pythonhosted.org/packages/53/22/470bb42f90505dc572f6bbcf3ac84d67aaf1554cd48cc08f788c36fec129/ttach-0.0.2-py3-none-any.whl\n",
      "Installing collected packages: ttach\n",
      "Successfully installed ttach-0.0.2\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ttach\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
=======
   "execution_count": 24,
>>>>>>> e58308043ccf82a4902fc482479be4e6e3beba4c
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder</th>\n",
       "      <th>Id</th>\n",
       "      <th>Field</th>\n",
       "      <th>Well</th>\n",
       "      <th>CoringTop</th>\n",
       "      <th>CoringDown</th>\n",
       "      <th>CoringTopBind</th>\n",
       "      <th>CoringDownBind</th>\n",
       "      <th>CoreRecovery</th>\n",
       "      <th>PhotoTop</th>\n",
       "      <th>PhotoDown</th>\n",
       "      <th>PhotoType</th>\n",
       "      <th>LayerTop</th>\n",
       "      <th>LayerDown</th>\n",
       "      <th>Rock</th>\n",
       "      <th>Carbonate</th>\n",
       "      <th>Ruin</th>\n",
       "      <th>Saturation</th>\n",
       "      <th>class</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unload2</td>\n",
       "      <td>1001901</td>\n",
       "      <td>Field1</td>\n",
       "      <td>Well3</td>\n",
       "      <td>2621.0</td>\n",
       "      <td>2638.0</td>\n",
       "      <td>2624.0</td>\n",
       "      <td>2641.0</td>\n",
       "      <td>16.85</td>\n",
       "      <td>2.93</td>\n",
       "      <td>3.91</td>\n",
       "      <td>УФ</td>\n",
       "      <td>2.63</td>\n",
       "      <td>5.34</td>\n",
       "      <td>песчаник</td>\n",
       "      <td>с карбонатными обломками или конкрециями</td>\n",
       "      <td>частично разрушен</td>\n",
       "      <td>нефтенасыщенные</td>\n",
       "      <td>1</td>\n",
       "      <td>9.367713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unload1</td>\n",
       "      <td>1001161</td>\n",
       "      <td>Field3</td>\n",
       "      <td>Well12</td>\n",
       "      <td>3175.1</td>\n",
       "      <td>3181.1</td>\n",
       "      <td>3176.3</td>\n",
       "      <td>3182.3</td>\n",
       "      <td>5.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.45</td>\n",
       "      <td>УФ</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.45</td>\n",
       "      <td>пересл. песчаника, алевролита и глин</td>\n",
       "      <td>с примесью</td>\n",
       "      <td>не разрушен</td>\n",
       "      <td>не опред.</td>\n",
       "      <td>0</td>\n",
       "      <td>1.369836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unload1</td>\n",
       "      <td>1001305</td>\n",
       "      <td>Field3</td>\n",
       "      <td>Well12</td>\n",
       "      <td>3252.0</td>\n",
       "      <td>3263.0</td>\n",
       "      <td>3253.5</td>\n",
       "      <td>3264.5</td>\n",
       "      <td>10.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>УФ</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.04</td>\n",
       "      <td>алевролит</td>\n",
       "      <td>слабокарбонатный</td>\n",
       "      <td>не разрушен</td>\n",
       "      <td>не опред.</td>\n",
       "      <td>0</td>\n",
       "      <td>1.369836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unload1</td>\n",
       "      <td>1001475</td>\n",
       "      <td>Field3</td>\n",
       "      <td>Well9</td>\n",
       "      <td>798.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>798.7</td>\n",
       "      <td>805.7</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.72</td>\n",
       "      <td>6.90</td>\n",
       "      <td>УФ</td>\n",
       "      <td>6.72</td>\n",
       "      <td>6.90</td>\n",
       "      <td>алевро-аргиллит</td>\n",
       "      <td>не карбонатный</td>\n",
       "      <td>не разрушен</td>\n",
       "      <td>не опред.</td>\n",
       "      <td>0</td>\n",
       "      <td>1.369836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unload2</td>\n",
       "      <td>1001097</td>\n",
       "      <td>Field8</td>\n",
       "      <td>Well14</td>\n",
       "      <td>2781.0</td>\n",
       "      <td>2799.0</td>\n",
       "      <td>2782.1</td>\n",
       "      <td>2800.1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>15.98</td>\n",
       "      <td>16.99</td>\n",
       "      <td>УФ</td>\n",
       "      <td>12.00</td>\n",
       "      <td>17.81</td>\n",
       "      <td>кремнисто-глинистая порода</td>\n",
       "      <td>не карбонатный</td>\n",
       "      <td>не разрушен</td>\n",
       "      <td>битуминозный</td>\n",
       "      <td>2</td>\n",
       "      <td>19.707547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Folder       Id   Field    Well  CoringTop  CoringDown  CoringTopBind  \\\n",
       "0  Unload2  1001901  Field1   Well3     2621.0      2638.0         2624.0   \n",
       "1  Unload1  1001161  Field3  Well12     3175.1      3181.1         3176.3   \n",
       "2  Unload1  1001305  Field3  Well12     3252.0      3263.0         3253.5   \n",
       "3  Unload1  1001475  Field3   Well9      798.0       805.0          798.7   \n",
       "4  Unload2  1001097  Field8  Well14     2781.0      2799.0         2782.1   \n",
       "\n",
       "   CoringDownBind  CoreRecovery  PhotoTop  PhotoDown PhotoType  LayerTop  \\\n",
       "0          2641.0         16.85      2.93       3.91        УФ      2.63   \n",
       "1          3182.3          5.98      1.00       1.45        УФ      0.90   \n",
       "2          3264.5         10.92      0.00       1.00        УФ      0.00   \n",
       "3           805.7          6.90      6.72       6.90        УФ      6.72   \n",
       "4          2800.1         17.99     15.98      16.99        УФ     12.00   \n",
       "\n",
       "   LayerDown                                  Rock  \\\n",
       "0       5.34                              песчаник   \n",
       "1       1.45  пересл. песчаника, алевролита и глин   \n",
       "2       4.04                             алевролит   \n",
       "3       6.90                       алевро-аргиллит   \n",
       "4      17.81            кремнисто-глинистая порода   \n",
       "\n",
       "                                  Carbonate               Ruin  \\\n",
       "0  с карбонатными обломками или конкрециями  частично разрушен   \n",
       "1                                с примесью        не разрушен   \n",
       "2                          слабокарбонатный        не разрушен   \n",
       "3                            не карбонатный        не разрушен   \n",
       "4                            не карбонатный        не разрушен   \n",
       "\n",
       "        Saturation  class     weight  \n",
       "0  нефтенасыщенные      1   9.367713  \n",
       "1        не опред.      0   1.369836  \n",
       "2        не опред.      0   1.369836  \n",
       "3        не опред.      0   1.369836  \n",
       "4     битуминозный      2  19.707547  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "uf = pd.read_csv(\"../data/train_data_uf.csv\")\n",
    "uf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Using device: cuda\n",
      "True\n",
      "Tesla V100-SXM2-16GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "==> Preparing data\n",
      "==> Preparing model\n",
      "Using cache found in /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "GenEfficientNet(\n",
      "  (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): ReLU(inplace=True)\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv_dw): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "        (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(72, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv_expand): Conv2d(6, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv_dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "        (bn2): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(120, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv_expand): Conv2d(10, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv_dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "        (bn2): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(120, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv_expand): Conv2d(10, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "        (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (bn2): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act2): ReLU(inplace=True)\n",
      "  (global_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Linear(in_features=1280, out_features=1000, bias=True)\n",
      ")\n",
      "1280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030\n",
      "==> Initialising sampler\n",
      "=====> Loading indices\n",
      "=====> Loading samples\n",
      "=====> Assigning weights\n",
      "100%|███████████████████████████████████| 2089/2089 [00:00<00:00, 117330.65it/s]\n",
      "==> Training model\n",
      "=====> Initial test\n",
      "100%|███████████████████████████████████████████| 33/33 [00:38<00:00,  1.18s/it]\n",
      "Rock-auc - 0.5115222806893303\n",
      "[288. 185. 576.] - count of true targets\n",
      "[ 22.   4. 989.] - count of predicted targets\n",
      "Test set: Average loss: 0.0218, F1: 0.2349, Test ROC-AUC: 0.512\n",
      "\n",
      "cuda:0\n",
      "wandb 0\n",
      "100%|███████████████████████████████████████████| 66/66 [01:29<00:00,  1.36s/it]\n",
      "[708. 788. 754.] - count of true targets\n",
      "[598. 704. 568.] - count of predicted targets\n",
      "Train Epoch: 0 \tLoss: 0.017233  My F1: 0.5744, AP: 0.6354, ROC-AUC: 0.764\n",
      "100%|███████████████████████████████████████████| 33/33 [00:40<00:00,  1.23s/it]\n",
      "Rock-auc - 0.8275906877219144\n",
      "[301. 209. 548.] - count of true targets\n",
      "[268. 222. 316.] - count of predicted targets\n",
      "Test set: Average loss: 0.0157, F1: 0.5704, Test ROC-AUC: 0.828\n",
      "\n",
      "cuda:0\n",
      "wandb 0\n",
      "  0%|                                                    | 0/66 [00:00<?, ?it/s]^C\n",
      "  0%|                                                    | 0/66 [00:02<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"../src/train_multilabel.py\", line 413, in <module>\n",
      "    main()\n",
      "  File \"../src/train_multilabel.py\", line 405, in main\n",
      "    train_loop(args)\n",
      "  File \"../src/train_multilabel.py\", line 367, in train_loop\n",
      "    train_len, train_loss = train(model, DEVICE, train_loader, optimizer, loss, epoch, name = NAME, num_classes=NUM_CLASSES, log_path = LOG_PATH, wandb_log = WANDB, treshold=TRESHOLD)\n",
      "  File \"../src/train_multilabel.py\", line 95, in train\n",
      "    batch_data = next(iterator)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 804, in __next__\n",
      "    idx, data = self._get_data()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 761, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 724, in _try_get_data\n",
      "    data = self.data_queue.get(timeout=timeout)\n",
      "  File \"/usr/lib/python3.6/queue.py\", line 173, in get\n",
      "    self.not_empty.wait(remaining)\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 299, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python -W ignore ../src/train_multilabel.py --tags \"5#att#squeeze#0.5#sum\" --base \"mnasnet_a1\" --image_size 224 --lr 1e-3 --epochs 500 \\\n",
    "--batch_size 32 --wandb 0 --path /project/ --num_classes 3 --treshold 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -W ignore ../src/train.py --tags \"1#squese\" --base \"efficientnet_b2\" --image_size 260 --wandb 1 --batch_size 42 --epochs 500 --inp_size 1480"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 19,
>>>>>>> e58308043ccf82a4902fc482479be4e6e3beba4c
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "==> Preparing data\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n",
      " 17%|██████▎                               | 7.44M/44.7M [00:00<00:03, 11.6MB/s]^C\n",
      " 23%|████████▊                             | 10.4M/44.7M [00:00<00:02, 15.4MB/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"../src/train.py\", line 286, in <module>\n",
      "    main()\n",
      "  File \"../src/train.py\", line 284, in main\n",
      "    train_loop(args)\n",
      "  File \"../src/train.py\", line 234, in train_loop\n",
      "    model, optimizer, loss = prepare_base_model(lr=LR, device=DEVICE, name=BASE, weight_decay=WD, beta_1=B1, beta_2=B2)\n",
      "  File \"/project/src/model.py\", line 148, in prepare_base_model\n",
      "    model = models.resnet18(pretrained=True)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\", line 231, in resnet18\n",
      "    **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\", line 217, in _resnet\n",
      "    progress=progress)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/hub.py\", line 462, in load_state_dict_from_url\n",
      "    _download_url_to_file(url, cached_file, hash_prefix, progress=progress)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/hub.py\", line 393, in _download_url_to_file\n",
      "    buffer = u.read(8192)\n",
      "  File \"/usr/lib/python3.6/http/client.py\", line 459, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"/usr/lib/python3.6/http/client.py\", line 503, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"/usr/lib/python3.6/socket.py\", line 586, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/usr/lib/python3.6/ssl.py\", line 1012, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/usr/lib/python3.6/ssl.py\", line 874, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "  File \"/usr/lib/python3.6/ssl.py\", line 631, in read\n",
      "    v = self._sslobj.read(len, buffer)\n",
      "KeyboardInterrupt\n"
=======
      "cuda\n",
      "Using device: cuda\n",
      "True\n",
      "Tesla V100-PCIE-32GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "==> Preparing data\n",
      "==> Preparing model\n",
      "Using cache found in /headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "Using cache found in /headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "Adding attention\n",
      "==> Initialising sampler\n",
      "=====> Loading indices\n",
      "=====> Loading samples\n",
      "=====> Checking distribution\n",
      "=====> Assigning weights\n",
      "100%|███████████████████████████████████████| 2565/2565 [08:54<00:00,  4.80it/s]\n",
      "==> Training model\n",
      "  0%|                                                    | 0/36 [00:08<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"../src/train.py\", line 382, in <module>\n",
      "    main()\n",
      "  File \"../src/train.py\", line 376, in main\n",
      "    train_loop(args)\n",
      "  File \"../src/train.py\", line 338, in train_loop\n",
      "    test_len = test(model, DEVICE, test_loader, loss, epoch, num_classes=NUM_CLASSES, wandb_log=WANDB)\n",
      "  File \"../src/train.py\", line 211, in test\n",
      "    output = model(data).cuda()\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/gen_efficientnet.py\", line 207, in forward\n",
      "    return self.classifier(x)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 92, in forward\n",
      "    input = module(input)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/nn/modules/pooling.py\", line 1031, in forward\n",
      "    return F.adaptive_avg_pool2d(input, self.output_size)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/nn/functional.py\", line 768, in adaptive_avg_pool2d\n",
      "    return torch._C._nn.adaptive_avg_pool2d(input, _output_size)\n",
      "RuntimeError: shape '[36, 54, 1, 1]' is invalid for input of size 1\n",
      "Exception in thread Thread-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/headless/miniconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/headless/miniconda3/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/headless/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\", line 294, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/headless/miniconda3/lib/python3.7/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/headless/miniconda3/lib/python3.7/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/headless/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 498, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/headless/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 746, in answer_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "  File \"/headless/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/headless/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/headless/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n"
>>>>>>> e58308043ccf82a4902fc482479be4e6e3beba4c
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "!python -W ignore ../src/train.py --tags \"3#drop0.2\" --base \"resnet18\" --image_size 128 --lr 1e-3 --epochs 200 \\\n",
    "--batch_size 8 --wandb 0"
=======
    "!python -W ignore ../src/train.py --tags \"3#drop0.2\" --base \"efficientnet_b0\" --image_size 128 --lr 1e-3 --epochs 200 \\\n",
    "--batch_size 36 --wandb 0"
>>>>>>> e58308043ccf82a4902fc482479be4e6e3beba4c
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 6])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from attention_augmented_conv import AugmentedConv\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "                      AugmentedConv(in_channels=1280, out_channels=6, kernel_size=1, dk=40, dv=4, Nh=1, relative=False, stride=2),\n",
    "                     #nn.Conv2d(588, 6, kernel_size=1, padding = 1, stride=1, bias=False),\n",
    "                     torch.nn.BatchNorm2d(6), \n",
    "                     torch.nn.Dropout(p=0.25),\n",
    "                     torch.nn.AdaptiveAvgPool2d(1)\n",
    "                      ).to(\"cuda\")\n",
    "temp_input = torch.randn((16, 1280, 32, 32)).to('cuda')\n",
    "augmented_conv = AugmentedConv(in_channels=1280, out_channels=6, kernel_size=1, dk=40, dv=4, Nh=1, relative=False, stride=2).to('cuda')\n",
    "norm = torch.nn.BatchNorm2d(6).to(\"cuda\")\n",
    "\n",
    "conv_out = model(temp_input).squeeze()\n",
    "print(conv_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Using device: cuda\n",
      "True\n",
      "Tesla V100-PCIE-32GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "wandb!\n",
<<<<<<< HEAD
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.8.16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.8.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in ../logs/wandb/run-20191204_091726-jsukwu9q\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m1#drop0.2_mixnet_s_ft_0.001_6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/nuvard/kern\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/nuvard/kern/runs/jsukwu9q\u001b[0m\n",
=======
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.8.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in ../../../shared/kern_segmentation/logs/wandb/run-20191207_222740-rqsiwlo7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m1#drop0.2_mixnet_s_ft_0.001_6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/nuvard/kern\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/nuvard/kern/runs/rqsiwlo7\u001b[0m\n",
>>>>>>> e58308043ccf82a4902fc482479be4e6e3beba4c
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "==> Preparing data\n",
      "==> Preparing model\n",
<<<<<<< HEAD
      "Downloading: \"https://github.com/rwightman/gen-efficientnet-pytorch/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n",
      "Using cache found in /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mixnet_s-a907afbc.pth\" to /root/.cache/torch/checkpoints/mixnet_s-a907afbc.pth\n",
      "GenEfficientNet(\n",
      "  (conv_stem): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): ReLU(inplace=True)\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pw): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(8, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(8, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(12, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(12, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv_dw): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "        (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(36, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(36, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "          (1): Conv2d(48, 48, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=48, bias=False)\n",
      "          (2): Conv2d(48, 48, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=48, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(144, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(12, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n",
      "          (1): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(240, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(20, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n",
      "          (1): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(240, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(20, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n",
      "          (1): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(240, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(20, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)\n",
      "          (1): Conv2d(80, 80, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=80, bias=False)\n",
      "          (2): Conv2d(80, 80, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=80, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
      "          (1): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
      "          (1): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
      "          (1): Conv2d(160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160, bias=False)\n",
      "          (2): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(480, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(40, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(240, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(240, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(60, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(60, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=90, bias=False)\n",
      "          (1): Conv2d(90, 90, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=90, bias=False)\n",
      "          (2): Conv2d(90, 90, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=90, bias=False)\n",
      "          (3): Conv2d(90, 90, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=90, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(360, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(60, 360, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(180, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(180, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(60, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(60, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=90, bias=False)\n",
      "          (1): Conv2d(90, 90, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=90, bias=False)\n",
      "          (2): Conv2d(90, 90, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=90, bias=False)\n",
      "          (3): Conv2d(90, 90, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=90, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(360, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(60, 360, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(180, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(180, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
      "          (2): Conv2d(144, 144, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=144, bias=False)\n",
      "          (3): Conv2d(144, 144, kernel_size=(9, 9), stride=(2, 2), padding=(4, 4), groups=144, bias=False)\n",
      "          (4): Conv2d(144, 144, kernel_size=(11, 11), stride=(2, 2), padding=(5, 5), groups=144, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(720, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(60, 720, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(720, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(300, 300, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=300, bias=False)\n",
      "          (1): Conv2d(300, 300, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=300, bias=False)\n",
      "          (2): Conv2d(300, 300, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=300, bias=False)\n",
      "          (3): Conv2d(300, 300, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=300, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(1200, 100, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(100, 1200, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(600, 100, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(600, 100, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(300, 300, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=300, bias=False)\n",
      "          (1): Conv2d(300, 300, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=300, bias=False)\n",
      "          (2): Conv2d(300, 300, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=300, bias=False)\n",
      "          (3): Conv2d(300, 300, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=300, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(1200, 100, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(100, 1200, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(600, 100, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(600, 100, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_head): Conv2d(200, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act2): ReLU(inplace=True)\n",
      "  (global_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Linear(in_features=1536, out_features=1000, bias=True)\n",
      ")\n",
      "GenEfficientNet(\n",
      "  (conv_stem): Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): ReLU(inplace=True)\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pw): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(8, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(8, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(12, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(12, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv_dw): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "        (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(36, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(36, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "          (1): Conv2d(48, 48, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=48, bias=False)\n",
      "          (2): Conv2d(48, 48, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=48, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(144, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(12, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n",
      "          (1): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(240, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(20, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n",
      "          (1): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(240, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(20, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n",
      "          (1): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(240, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(20, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)\n",
      "          (1): Conv2d(80, 80, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=80, bias=False)\n",
      "          (2): Conv2d(80, 80, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=80, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
      "          (1): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
      "          (1): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
      "          (1): Conv2d(160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160, bias=False)\n",
      "          (2): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(480, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(40, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(240, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(240, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(60, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(60, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=90, bias=False)\n",
      "          (1): Conv2d(90, 90, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=90, bias=False)\n",
      "          (2): Conv2d(90, 90, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=90, bias=False)\n",
      "          (3): Conv2d(90, 90, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=90, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(360, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(60, 360, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(180, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(180, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(60, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(60, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=90, bias=False)\n",
      "          (1): Conv2d(90, 90, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=90, bias=False)\n",
      "          (2): Conv2d(90, 90, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=90, bias=False)\n",
      "          (3): Conv2d(90, 90, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=90, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(360, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(60, 360, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(180, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(180, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
      "          (2): Conv2d(144, 144, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=144, bias=False)\n",
      "          (3): Conv2d(144, 144, kernel_size=(9, 9), stride=(2, 2), padding=(4, 4), groups=144, bias=False)\n",
      "          (4): Conv2d(144, 144, kernel_size=(11, 11), stride=(2, 2), padding=(5, 5), groups=144, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(720, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(60, 720, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(720, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(300, 300, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=300, bias=False)\n",
      "          (1): Conv2d(300, 300, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=300, bias=False)\n",
      "          (2): Conv2d(300, 300, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=300, bias=False)\n",
      "          (3): Conv2d(300, 300, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=300, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(1200, 100, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(100, 1200, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(600, 100, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(600, 100, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(300, 300, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=300, bias=False)\n",
      "          (1): Conv2d(300, 300, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=300, bias=False)\n",
      "          (2): Conv2d(300, 300, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=300, bias=False)\n",
      "          (3): Conv2d(300, 300, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=300, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(1200, 100, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(100, 1200, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(600, 100, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(600, 100, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_head): Conv2d(200, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act2): ReLU(inplace=True)\n",
      "  (global_pool): Sequential(\n",
      "    (0): AdaptiveAvgPool2d(output_size=1)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.25, inplace=False)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=1536, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Initialising sampler\n",
      "=====> Loading indices\n",
      "=====> Loading samples\n",
      "=====> Checking distribution\n",
      "100%|███████████████████████████████████████| 2565/2565 [06:09<00:00,  6.94it/s]\n",
      "=====> Assigning weights\n",
      "100%|███████████████████████████████████████| 2565/2565 [06:05<00:00,  7.01it/s]\n",
      "==> Training model\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:29<00:00,  1.44s/it]\n",
      "1\n",
      "Train Epoch: 0 \tLoss: 0.025671    F1: 0.6131    My F1: 0.6131, AP: 0.6102\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.82s/it]\n",
      "\n",
      "Test set: Average loss: 0.0213, F1: 0.5594\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.49s/it]\n",
      "1\n",
      "Train Epoch: 1 \tLoss: 0.021836    F1: 0.6635    My F1: 0.6635, AP: 0.6632\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.73s/it]\n",
      "\n",
      "Test set: Average loss: 0.0223, F1: 0.5581\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:34<00:00,  1.53s/it]\n",
      "1\n",
      "Train Epoch: 2 \tLoss: 0.021797    F1: 0.6674    My F1: 0.6674, AP: 0.6679\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.81s/it]\n",
      "\n",
      "Test set: Average loss: 0.0237, F1: 0.5384\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:33<00:00,  1.50s/it]\n",
      "1\n",
      "Train Epoch: 3 \tLoss: 0.022260    F1: 0.6709    My F1: 0.6709, AP: 0.6709\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.78s/it]\n",
      "\n",
      "Test set: Average loss: 0.0212, F1: 0.5756\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:31<00:00,  1.47s/it]\n",
      "1\n",
      "Train Epoch: 4 \tLoss: 0.022378    F1: 0.6990    My F1: 0.6990, AP: 0.6998\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.86s/it]\n",
      "\n",
      "Test set: Average loss: 0.0209, F1: 0.5770\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.48s/it]\n",
      "1\n",
      "Train Epoch: 5 \tLoss: 0.019264    F1: 0.7080    My F1: 0.7080, AP: 0.7069\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.73s/it]\n",
      "\n",
      "Test set: Average loss: 0.0182, F1: 0.6263\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.46s/it]\n",
      "1\n",
      "Train Epoch: 6 \tLoss: 0.019247    F1: 0.7079    My F1: 0.7079, AP: 0.7085\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.83s/it]\n",
      "\n",
      "Test set: Average loss: 0.0193, F1: 0.6069\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:27<00:00,  1.41s/it]\n",
      "1\n",
      "Train Epoch: 7 \tLoss: 0.017727    F1: 0.7415    My F1: 0.7415, AP: 0.7410\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.86s/it]\n",
      "\n",
      "Test set: Average loss: 0.0182, F1: 0.6231\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:34<00:00,  1.53s/it]\n",
      "1\n",
      "Train Epoch: 8 \tLoss: 0.016615    F1: 0.7483    My F1: 0.7483, AP: 0.7481\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.75s/it]\n",
      "\n",
      "Test set: Average loss: 0.0191, F1: 0.6109\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:25<00:00,  1.38s/it]\n",
      "1\n",
      "Train Epoch: 9 \tLoss: 0.017761    F1: 0.7329    My F1: 0.7329, AP: 0.7313\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.74s/it]\n",
      "\n",
      "Test set: Average loss: 0.0168, F1: 0.6323\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.49s/it]\n",
      "1\n",
      "Train Epoch: 10 \tLoss: 0.018176    F1: 0.7308    My F1: 0.7308, AP: 0.7311\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.85s/it]\n",
      "\n",
      "Test set: Average loss: 0.0160, F1: 0.5824\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:28<00:00,  1.43s/it]\n",
      "1\n",
      "Train Epoch: 11 \tLoss: 0.016921    F1: 0.7529    My F1: 0.7529, AP: 0.7535\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.79s/it]\n",
      "\n",
      "Test set: Average loss: 0.0216, F1: 0.5769\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:25<00:00,  1.38s/it]\n",
      "1\n",
      "Train Epoch: 12 \tLoss: 0.017444    F1: 0.7529    My F1: 0.7529, AP: 0.7532\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.72s/it]\n",
      "\n",
      "Test set: Average loss: 0.0246, F1: 0.5166\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.49s/it]\n",
      "1\n",
      "Train Epoch: 13 \tLoss: 0.018597    F1: 0.7382    My F1: 0.7382, AP: 0.7382\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.77s/it]\n",
      "\n",
      "Test set: Average loss: 0.0171, F1: 0.5931\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:31<00:00,  1.47s/it]\n",
      "1\n",
      "Train Epoch: 14 \tLoss: 0.018329    F1: 0.7440    My F1: 0.7440, AP: 0.7431\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.82s/it]\n",
      "\n",
      "Test set: Average loss: 0.0160, F1: 0.6461\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.45s/it]\n",
      "1\n",
      "Train Epoch: 15 \tLoss: 0.018337    F1: 0.7255    My F1: 0.7255, AP: 0.7251\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.79s/it]\n",
      "\n",
      "Test set: Average loss: 0.0173, F1: 0.6755\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:29<00:00,  1.44s/it]\n",
      "1\n",
      "Train Epoch: 16 \tLoss: 0.018513    F1: 0.7397    My F1: 0.7397, AP: 0.7409\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.71s/it]\n",
      "\n",
      "Test set: Average loss: 0.0166, F1: 0.6066\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:28<00:00,  1.42s/it]\n",
      "1\n",
      "Train Epoch: 17 \tLoss: 0.016635    F1: 0.7517    My F1: 0.7517, AP: 0.7525\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.69s/it]\n",
      "\n",
      "Test set: Average loss: 0.0158, F1: 0.6459\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:29<00:00,  1.45s/it]\n",
      "1\n",
      "Train Epoch: 18 \tLoss: 0.015819    F1: 0.7642    My F1: 0.7642, AP: 0.7641\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.76s/it]\n",
      "\n",
      "Test set: Average loss: 0.0135, F1: 0.6672\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.49s/it]\n",
      "1\n",
      "Train Epoch: 20 \tLoss: 0.015869    F1: 0.7582    My F1: 0.7582, AP: 0.7590\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.83s/it]\n",
      "\n",
      "Test set: Average loss: 0.0134, F1: 0.6720\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:31<00:00,  1.47s/it]\n",
      "1\n",
      "Train Epoch: 21 \tLoss: 0.016921    F1: 0.7524    My F1: 0.7524, AP: 0.7525\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.70s/it]\n",
      "\n",
      "Test set: Average loss: 0.0144, F1: 0.6205\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:31<00:00,  1.47s/it]\n",
      "1\n",
      "Train Epoch: 22 \tLoss: 0.015071    F1: 0.7609    My F1: 0.7609, AP: 0.7616\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.85s/it]\n",
      "\n",
      "Test set: Average loss: 0.0143, F1: 0.6568\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.50s/it]\n",
      "1\n",
      "Train Epoch: 23 \tLoss: 0.015200    F1: 0.7739    My F1: 0.7739, AP: 0.7753\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.77s/it]\n",
      "\n",
      "Test set: Average loss: 0.0166, F1: 0.6379\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.48s/it]\n",
      "1\n",
      "Train Epoch: 24 \tLoss: 0.017259    F1: 0.7591    My F1: 0.7591, AP: 0.7600\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.76s/it]\n",
      "\n",
      "Test set: Average loss: 0.0157, F1: 0.6290\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:27<00:00,  1.41s/it]\n",
      "1\n",
      "Train Epoch: 25 \tLoss: 0.017393    F1: 0.7474    My F1: 0.7474, AP: 0.7485\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.76s/it]\n",
      "\n",
      "Test set: Average loss: 0.0183, F1: 0.6365\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:27<00:00,  1.41s/it]\n",
      "1\n",
      "Train Epoch: 26 \tLoss: 0.016669    F1: 0.7481    My F1: 0.7481, AP: 0.7473\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.81s/it]\n",
      "\n",
      "Test set: Average loss: 0.0172, F1: 0.6064\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:31<00:00,  1.47s/it]\n",
      "1\n",
      "Train Epoch: 27 \tLoss: 0.015951    F1: 0.7607    My F1: 0.7607, AP: 0.7606\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.77s/it]\n",
      "\n",
      "Test set: Average loss: 0.0168, F1: 0.6255\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.46s/it]\n",
      "1\n",
      "Train Epoch: 28 \tLoss: 0.014772    F1: 0.7767    My F1: 0.7767, AP: 0.7772\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.73s/it]\n",
      "\n",
      "Test set: Average loss: 0.0164, F1: 0.6592\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:29<00:00,  1.44s/it]\n",
      "1\n",
      "Train Epoch: 29 \tLoss: 0.016142    F1: 0.7609    My F1: 0.7609, AP: 0.7605\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.78s/it]\n",
      "\n",
      "Test set: Average loss: 0.0225, F1: 0.5733\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:26<00:00,  1.39s/it]\n",
      "1\n",
      "Train Epoch: 30 \tLoss: 0.017022    F1: 0.7484    My F1: 0.7484, AP: 0.7489\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.73s/it]\n",
      "\n",
      "Test set: Average loss: 0.0179, F1: 0.5937\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:25<00:00,  1.38s/it]\n",
      "1\n",
      "Train Epoch: 31 \tLoss: 0.018687    F1: 0.7160    My F1: 0.7160, AP: 0.7156\n",
      "100%|███████████████████████████████████████████| 16/16 [00:26<00:00,  1.67s/it]\n",
      "\n",
      "Test set: Average loss: 0.0168, F1: 0.6022\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:29<00:00,  1.44s/it]\n",
      "1\n",
      "Train Epoch: 32 \tLoss: 0.015147    F1: 0.7711    My F1: 0.7711, AP: 0.7713\n",
      "100%|███████████████████████████████████████████| 16/16 [00:26<00:00,  1.67s/it]\n",
      "\n",
      "Test set: Average loss: 0.0155, F1: 0.6895\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:27<00:00,  1.41s/it]\n",
      "1\n",
      "Train Epoch: 33 \tLoss: 0.016652    F1: 0.7440    My F1: 0.7440, AP: 0.7439\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.72s/it]\n",
      "\n",
      "Test set: Average loss: 0.0174, F1: 0.6169\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:26<00:00,  1.40s/it]\n",
      "1\n",
      "Train Epoch: 34 \tLoss: 0.014667    F1: 0.7787    My F1: 0.7787, AP: 0.7790\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.71s/it]\n",
      "\n",
      "Test set: Average loss: 0.0148, F1: 0.6561\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:23<00:00,  1.35s/it]\n",
      "1\n",
      "Train Epoch: 35 \tLoss: 0.015505    F1: 0.7602    My F1: 0.7602, AP: 0.7599\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.69s/it]\n",
      "\n",
      "Test set: Average loss: 0.0159, F1: 0.6388\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:28<00:00,  1.42s/it]\n",
      "1\n",
      "Train Epoch: 36 \tLoss: 0.017785    F1: 0.7350    My F1: 0.7350, AP: 0.7353\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.70s/it]\n",
      "\n",
      "Test set: Average loss: 0.0205, F1: 0.5887\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.47s/it]\n",
      "1\n",
      "Train Epoch: 37 \tLoss: 0.015925    F1: 0.7607    My F1: 0.7607, AP: 0.7607\n",
      "100%|███████████████████████████████████████████| 16/16 [00:26<00:00,  1.66s/it]\n",
      "\n",
      "Test set: Average loss: 0.0187, F1: 0.6118\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:28<00:00,  1.43s/it]\n",
      "1\n",
      "Train Epoch: 38 \tLoss: 0.015971    F1: 0.7704    My F1: 0.7704, AP: 0.7704\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.75s/it]\n",
      "\n",
      "Test set: Average loss: 0.0153, F1: 0.6295\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.45s/it]\n",
      "1\n",
      "Train Epoch: 39 \tLoss: 0.015928    F1: 0.7500    My F1: 0.7500, AP: 0.7492\n",
      "100%|███████████████████████████████████████████| 62/62 [01:26<00:00,  1.39s/it]\n",
      "1\n",
      "Train Epoch: 56 \tLoss: 0.016823    F1: 0.7622    My F1: 0.7622, AP: 0.7639\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.69s/it]\n",
      "\n",
      "Test set: Average loss: 0.0185, F1: 0.5960\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:26<00:00,  1.40s/it]\n",
      "1\n",
      "Train Epoch: 57 \tLoss: 0.015639    F1: 0.7752    My F1: 0.7752, AP: 0.7750\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.87s/it]\n",
      "\n",
      "Test set: Average loss: 0.0164, F1: 0.6541\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.46s/it]\n",
      "1\n",
      "Train Epoch: 58 \tLoss: 0.016165    F1: 0.7632    My F1: 0.7632, AP: 0.7622\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.78s/it]\n",
      "\n",
      "Test set: Average loss: 0.0142, F1: 0.6401\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:25<00:00,  1.38s/it]\n",
      "1\n",
      "Train Epoch: 59 \tLoss: 0.016216    F1: 0.7605    My F1: 0.7605, AP: 0.7595\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.75s/it]\n",
      "\n",
      "Test set: Average loss: 0.0193, F1: 0.6088\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:27<00:00,  1.42s/it]\n",
      "1\n",
      "Train Epoch: 60 \tLoss: 0.015052    F1: 0.7745    My F1: 0.7745, AP: 0.7757\n",
      "100%|███████████████████████████████████████████| 16/16 [00:26<00:00,  1.67s/it]\n",
      "\n",
      "Test set: Average loss: 0.0171, F1: 0.6402\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:27<00:00,  1.41s/it]\n",
      "1\n",
      "Train Epoch: 61 \tLoss: 0.016754    F1: 0.7612    My F1: 0.7612, AP: 0.7617\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.75s/it]\n",
      "\n",
      "Test set: Average loss: 0.0180, F1: 0.5912\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:29<00:00,  1.44s/it]\n",
      "1\n",
      "Train Epoch: 62 \tLoss: 0.014363    F1: 0.7926    My F1: 0.7926, AP: 0.7929\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.74s/it]\n",
      "\n",
      "Test set: Average loss: 0.0172, F1: 0.6139\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:31<00:00,  1.47s/it]\n",
      "1\n",
      "Train Epoch: 63 \tLoss: 0.015589    F1: 0.7725    My F1: 0.7725, AP: 0.7724\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.75s/it]\n",
      "\n",
      "Test set: Average loss: 0.0199, F1: 0.6231\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:31<00:00,  1.47s/it]\n",
      "1\n",
      "Train Epoch: 64 \tLoss: 0.016033    F1: 0.7630    My F1: 0.7630, AP: 0.7628\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.80s/it]\n",
      "\n",
      "Test set: Average loss: 0.0164, F1: 0.6425\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:37<00:00,  1.57s/it]\n",
      "1\n",
      "Train Epoch: 65 \tLoss: 0.015113    F1: 0.7653    My F1: 0.7653, AP: 0.7668\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.82s/it]\n",
      "\n",
      "Test set: Average loss: 0.0166, F1: 0.6048\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:37<00:00,  1.57s/it]\n",
      "1\n",
      "Train Epoch: 66 \tLoss: 0.014337    F1: 0.7736    My F1: 0.7736, AP: 0.7743\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.78s/it]\n",
      "\n",
      "Test set: Average loss: 0.0168, F1: 0.6439\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.49s/it]\n",
      "1\n",
      "Train Epoch: 67 \tLoss: 0.016832    F1: 0.7501    My F1: 0.7501, AP: 0.7502\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.82s/it]\n",
      "\n",
      "Test set: Average loss: 0.0160, F1: 0.6368\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:28<00:00,  1.43s/it]\n",
      "1\n",
      "Train Epoch: 68 \tLoss: 0.016317    F1: 0.7590    My F1: 0.7590, AP: 0.7608\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.72s/it]\n",
      "\n",
      "Test set: Average loss: 0.0182, F1: 0.5859\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:27<00:00,  1.41s/it]\n",
      "1\n",
      "Train Epoch: 69 \tLoss: 0.017624    F1: 0.7467    My F1: 0.7467, AP: 0.7462\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.69s/it]\n",
      "\n",
      "Test set: Average loss: 0.0181, F1: 0.6291\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:26<00:00,  1.40s/it]\n",
      "1\n",
      "Train Epoch: 70 \tLoss: 0.015005    F1: 0.7837    My F1: 0.7836, AP: 0.7843\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.78s/it]\n",
      "\n",
      "Test set: Average loss: 0.0155, F1: 0.6238\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:31<00:00,  1.48s/it]\n",
      "1\n",
      "Train Epoch: 71 \tLoss: 0.014342    F1: 0.7808    My F1: 0.7808, AP: 0.7803\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.76s/it]\n",
      "\n",
      "Test set: Average loss: 0.0150, F1: 0.6705\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:33<00:00,  1.51s/it]\n",
      "1\n",
      "Train Epoch: 72 \tLoss: 0.014767    F1: 0.7844    My F1: 0.7844, AP: 0.7855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.85s/it]\n",
      "\n",
      "Test set: Average loss: 0.0171, F1: 0.6092\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.46s/it]\n",
      "1\n",
      "Train Epoch: 73 \tLoss: 0.015733    F1: 0.7704    My F1: 0.7704, AP: 0.7698\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.79s/it]\n",
      "\n",
      "Test set: Average loss: 0.0176, F1: 0.5948\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.47s/it]\n",
      "1\n",
      "Train Epoch: 74 \tLoss: 0.015645    F1: 0.7610    My F1: 0.7610, AP: 0.7609\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.77s/it]\n",
      "\n",
      "Test set: Average loss: 0.0158, F1: 0.6364\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:35<00:00,  1.53s/it]\n",
      "1\n",
      "Train Epoch: 75 \tLoss: 0.014287    F1: 0.7805    My F1: 0.7805, AP: 0.7803\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.72s/it]\n",
      "\n",
      "Test set: Average loss: 0.0155, F1: 0.6887\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:27<00:00,  1.42s/it]\n",
      "1\n",
      "Train Epoch: 76 \tLoss: 0.014333    F1: 0.7885    My F1: 0.7885, AP: 0.7894\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.76s/it]\n",
      "\n",
      "Test set: Average loss: 0.0178, F1: 0.6247\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:31<00:00,  1.47s/it]\n",
      "1\n",
      "Train Epoch: 77 \tLoss: 0.016657    F1: 0.7374    My F1: 0.7374, AP: 0.7387\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.77s/it]\n",
      "\n",
      "Test set: Average loss: 0.0180, F1: 0.6089\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:28<00:00,  1.42s/it]\n",
      "1\n",
      "Train Epoch: 78 \tLoss: 0.014341    F1: 0.7851    My F1: 0.7851, AP: 0.7854\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.74s/it]\n",
      "\n",
      "Test set: Average loss: 0.0162, F1: 0.6505\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:29<00:00,  1.44s/it]\n",
      "1\n",
      "Train Epoch: 79 \tLoss: 0.016206    F1: 0.7756    My F1: 0.7756, AP: 0.7756\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.85s/it]\n",
      "\n",
      "Test set: Average loss: 0.0143, F1: 0.6276\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:26<00:00,  1.39s/it]\n",
      "1\n",
      "Train Epoch: 80 \tLoss: 0.015975    F1: 0.7611    My F1: 0.7611, AP: 0.7623\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.73s/it]\n",
      "\n",
      "Test set: Average loss: 0.0198, F1: 0.5568\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:31<00:00,  1.48s/it]\n",
      "1\n",
      "Train Epoch: 81 \tLoss: 0.015142    F1: 0.7819    My F1: 0.7819, AP: 0.7815\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.77s/it]\n",
      "\n",
      "Test set: Average loss: 0.0155, F1: 0.6183\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.49s/it]\n",
      "1\n",
      "Train Epoch: 82 \tLoss: 0.015567    F1: 0.7682    My F1: 0.7682, AP: 0.7682\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.74s/it]\n",
      "\n",
      "Test set: Average loss: 0.0173, F1: 0.6361\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.49s/it]\n",
      "1\n",
      "Train Epoch: 83 \tLoss: 0.014581    F1: 0.7752    My F1: 0.7752, AP: 0.7754\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.75s/it]\n",
      "\n",
      "Test set: Average loss: 0.0168, F1: 0.6188\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:26<00:00,  1.40s/it]\n",
      "1\n",
      "Train Epoch: 84 \tLoss: 0.014732    F1: 0.7839    My F1: 0.7839, AP: 0.7830\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.72s/it]\n",
      "\n",
      "Test set: Average loss: 0.0151, F1: 0.6596\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:35<00:00,  1.55s/it]\n",
      "1\n",
      "Train Epoch: 85 \tLoss: 0.014571    F1: 0.7969    My F1: 0.7969, AP: 0.7981\n",
      "100%|███████████████████████████████████████████| 16/16 [00:31<00:00,  1.96s/it]\n",
      "\n",
      "Test set: Average loss: 0.0146, F1: 0.6508\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:36<00:00,  1.56s/it]\n",
      "1\n",
      "Train Epoch: 86 \tLoss: 0.014614    F1: 0.7780    My F1: 0.7780, AP: 0.7774\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.74s/it]\n",
      "\n",
      "Test set: Average loss: 0.0171, F1: 0.5980\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.46s/it]\n",
      "1\n",
      "Train Epoch: 87 \tLoss: 0.015338    F1: 0.7742    My F1: 0.7742, AP: 0.7745\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.84s/it]\n",
      "\n",
      "Test set: Average loss: 0.0160, F1: 0.6319\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:34<00:00,  1.52s/it]\n",
      "1\n",
      "Train Epoch: 89 \tLoss: 0.014712    F1: 0.7828    My F1: 0.7828, AP: 0.7824\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.81s/it]\n",
      "\n",
      "Test set: Average loss: 0.0168, F1: 0.6473\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:34<00:00,  1.52s/it]\n",
      "1\n",
      "Train Epoch: 90 \tLoss: 0.014205    F1: 0.7861    My F1: 0.7861, AP: 0.7857\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.75s/it]\n",
      "\n",
      "Test set: Average loss: 0.0136, F1: 0.6674\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:34<00:00,  1.53s/it]\n",
      "1\n",
      "Train Epoch: 91 \tLoss: 0.014577    F1: 0.7831    My F1: 0.7831, AP: 0.7837\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.77s/it]\n",
      "\n",
      "Test set: Average loss: 0.0211, F1: 0.5471\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.50s/it]\n",
      "1\n",
      "Train Epoch: 92 \tLoss: 0.014182    F1: 0.7837    My F1: 0.7837, AP: 0.7820\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.78s/it]\n",
      "\n",
      "Test set: Average loss: 0.0195, F1: 0.6234\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.45s/it]\n",
      "1\n",
      "Train Epoch: 93 \tLoss: 0.013196    F1: 0.7876    My F1: 0.7876, AP: 0.7882\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.74s/it]\n",
      "\n",
      "Test set: Average loss: 0.0187, F1: 0.5945\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:26<00:00,  1.39s/it]\n",
      "1\n",
      "Train Epoch: 94 \tLoss: 0.013760    F1: 0.7978    My F1: 0.7978, AP: 0.7977\n",
      "100%|███████████████████████████████████████████| 16/16 [00:26<00:00,  1.68s/it]\n",
      "\n",
      "Test set: Average loss: 0.0175, F1: 0.6184\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:31<00:00,  1.47s/it]\n",
      "1\n",
      "Train Epoch: 95 \tLoss: 0.015158    F1: 0.7687    My F1: 0.7687, AP: 0.7688\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.72s/it]\n",
      "\n",
      "Test set: Average loss: 0.0129, F1: 0.6746\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.46s/it]\n",
      "1\n",
      "Train Epoch: 96 \tLoss: 0.014320    F1: 0.7775    My F1: 0.7775, AP: 0.7777\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.70s/it]\n",
      "\n",
      "Test set: Average loss: 0.0174, F1: 0.6162\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:31<00:00,  1.47s/it]\n",
      "1\n",
      "Train Epoch: 97 \tLoss: 0.013683    F1: 0.7977    My F1: 0.7977, AP: 0.7978\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.82s/it]\n",
      "\n",
      "Test set: Average loss: 0.0173, F1: 0.6338\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.45s/it]\n",
      "1\n",
      "Train Epoch: 98 \tLoss: 0.013506    F1: 0.7991    My F1: 0.7991, AP: 0.7999\n",
      "100%|███████████████████████████████████████████| 16/16 [00:31<00:00,  1.95s/it]\n",
      "\n",
      "Test set: Average loss: 0.0147, F1: 0.6560\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:25<00:00,  1.38s/it]\n",
      "1\n",
      "Train Epoch: 99 \tLoss: 0.014853    F1: 0.7711    My F1: 0.7711, AP: 0.7709\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.75s/it]\n",
      "\n",
      "Test set: Average loss: 0.0207, F1: 0.5563\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:28<00:00,  1.42s/it]\n",
      "1\n",
      "Train Epoch: 100 \tLoss: 0.013644    F1: 0.8000    My F1: 0.8000, AP: 0.7995\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.69s/it]\n",
      "\n",
      "Test set: Average loss: 0.0188, F1: 0.5818\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:34<00:00,  1.52s/it]\n",
      "1\n",
      "Train Epoch: 101 \tLoss: 0.014642    F1: 0.7809    My F1: 0.7809, AP: 0.7802\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.82s/it]\n",
      "\n",
      "Test set: Average loss: 0.0165, F1: 0.6330\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:33<00:00,  1.51s/it]\n",
      "1\n",
      "Train Epoch: 102 \tLoss: 0.014650    F1: 0.7978    My F1: 0.7978, AP: 0.7983\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.77s/it]\n",
      "\n",
      "Test set: Average loss: 0.0181, F1: 0.5914\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.46s/it]\n",
      "1\n",
      "Train Epoch: 103 \tLoss: 0.014342    F1: 0.7894    My F1: 0.7894, AP: 0.7899\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.72s/it]\n",
      "\n",
      "Test set: Average loss: 0.0166, F1: 0.6173\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:34<00:00,  1.52s/it]\n",
      "1\n",
      "Train Epoch: 104 \tLoss: 0.016251    F1: 0.7621    My F1: 0.7621, AP: 0.7620\n",
      "100%|███████████████████████████████████████████| 16/16 [00:30<00:00,  1.90s/it]\n",
      "\n",
      "Test set: Average loss: 0.0192, F1: 0.6203\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:33<00:00,  1.51s/it]\n",
      "1\n",
      "Train Epoch: 105 \tLoss: 0.014522    F1: 0.7760    My F1: 0.7760, AP: 0.7749\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.79s/it]\n",
      "\n",
      "Test set: Average loss: 0.0183, F1: 0.6253\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:35<00:00,  1.53s/it]\n",
      "1\n",
      "Train Epoch: 106 \tLoss: 0.013065    F1: 0.7929    My F1: 0.7929, AP: 0.7933\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.74s/it]\n",
      "\n",
      "Test set: Average loss: 0.0157, F1: 0.6418\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:33<00:00,  1.50s/it]\n",
      "1\n",
      "Train Epoch: 107 \tLoss: 0.014746    F1: 0.7809    My F1: 0.7809, AP: 0.7822\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.77s/it]\n",
      "\n",
      "Test set: Average loss: 0.0186, F1: 0.6366\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.46s/it]\n",
      "1\n",
      "Train Epoch: 108 \tLoss: 0.014308    F1: 0.7792    My F1: 0.7792, AP: 0.7794\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.78s/it]\n",
      "\n",
      "Test set: Average loss: 0.0159, F1: 0.6142\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:35<00:00,  1.54s/it]\n",
      "1\n",
      "Train Epoch: 109 \tLoss: 0.013666    F1: 0.7912    My F1: 0.7912, AP: 0.7908\n",
      "100%|███████████████████████████████████████████| 16/16 [00:32<00:00,  2.04s/it]\n",
      "\n",
      "Test set: Average loss: 0.0174, F1: 0.6358\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.46s/it]\n",
      "1\n",
      "Train Epoch: 110 \tLoss: 0.013590    F1: 0.7958    My F1: 0.7958, AP: 0.7956\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.70s/it]\n",
      "\n",
      "Test set: Average loss: 0.0137, F1: 0.6877\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:28<00:00,  1.43s/it]\n",
      "1\n",
      "Train Epoch: 111 \tLoss: 0.014000    F1: 0.7965    My F1: 0.7965, AP: 0.7962\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.69s/it]\n",
      "\n",
      "Test set: Average loss: 0.0179, F1: 0.6074\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:33<00:00,  1.51s/it]\n",
      "1\n",
      "Train Epoch: 112 \tLoss: 0.014191    F1: 0.8073    My F1: 0.8073, AP: 0.8066\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.71s/it]\n",
      "\n",
      "Test set: Average loss: 0.0156, F1: 0.6384\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:28<00:00,  1.43s/it]\n",
      "1\n",
      "Train Epoch: 113 \tLoss: 0.014006    F1: 0.7893    My F1: 0.7893, AP: 0.7899\n",
      "100%|███████████████████████████████████████████| 16/16 [00:30<00:00,  1.89s/it]\n",
      "\n",
      "Test set: Average loss: 0.0183, F1: 0.6235\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:29<00:00,  1.44s/it]\n",
      "1\n",
      "Train Epoch: 114 \tLoss: 0.014458    F1: 0.7910    My F1: 0.7910, AP: 0.7900\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.82s/it]\n",
      "\n",
      "Test set: Average loss: 0.0163, F1: 0.6175\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:29<00:00,  1.44s/it]\n",
      "1\n",
      "Train Epoch: 115 \tLoss: 0.014509    F1: 0.7854    My F1: 0.7854, AP: 0.7849\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.80s/it]\n",
      "\n",
      "Test set: Average loss: 0.0161, F1: 0.6351\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.46s/it]\n",
      "1\n",
      "Train Epoch: 116 \tLoss: 0.013885    F1: 0.7970    My F1: 0.7970, AP: 0.7970\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.73s/it]\n",
      "\n",
      "Test set: Average loss: 0.0148, F1: 0.6467\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:29<00:00,  1.44s/it]\n",
      "1\n",
      "Train Epoch: 117 \tLoss: 0.014728    F1: 0.7858    My F1: 0.7858, AP: 0.7864\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.82s/it]\n",
      "\n",
      "Test set: Average loss: 0.0151, F1: 0.6639\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:35<00:00,  1.54s/it]\n",
      "1\n",
      "Train Epoch: 118 \tLoss: 0.013339    F1: 0.8034    My F1: 0.8034, AP: 0.8045\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.83s/it]\n",
      "\n",
      "Test set: Average loss: 0.0157, F1: 0.6683\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.46s/it]\n",
      "1\n",
      "Train Epoch: 119 \tLoss: 0.014361    F1: 0.7884    My F1: 0.7884, AP: 0.7899\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.76s/it]\n",
      "\n",
      "Test set: Average loss: 0.0169, F1: 0.6151\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.49s/it]\n",
      "1\n",
      "Train Epoch: 120 \tLoss: 0.014863    F1: 0.7721    My F1: 0.7721, AP: 0.7717\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.73s/it]\n",
      "\n",
      "Test set: Average loss: 0.0227, F1: 0.5804\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:27<00:00,  1.42s/it]\n",
      "1\n",
      "Train Epoch: 121 \tLoss: 0.014332    F1: 0.7908    My F1: 0.7908, AP: 0.7904\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.77s/it]\n",
      "\n",
      "Test set: Average loss: 0.0159, F1: 0.6135\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:29<00:00,  1.45s/it]\n",
      "1\n",
      "Train Epoch: 122 \tLoss: 0.016058    F1: 0.7624    My F1: 0.7624, AP: 0.7619\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.69s/it]\n",
      "\n",
      "Test set: Average loss: 0.0175, F1: 0.6298\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.50s/it]\n",
      "1\n",
      "Train Epoch: 123 \tLoss: 0.014907    F1: 0.7776    My F1: 0.7776, AP: 0.7768\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.72s/it]\n",
      "\n",
      "Test set: Average loss: 0.0173, F1: 0.6374\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.45s/it]\n",
      "1\n",
      "Train Epoch: 124 \tLoss: 0.013922    F1: 0.7955    My F1: 0.7955, AP: 0.7957\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.72s/it]\n",
      "\n",
      "Test set: Average loss: 0.0135, F1: 0.7004\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:27<00:00,  1.41s/it]\n",
      "1\n",
      "Train Epoch: 125 \tLoss: 0.014071    F1: 0.7872    My F1: 0.7872, AP: 0.7866\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.75s/it]\n",
      "\n",
      "Test set: Average loss: 0.0159, F1: 0.6270\n",
      "\n",
      "wandb 1\n",
      " 19%|████████▎                                  | 12/62 [00:19<00:53,  1.06s/it]"
=======
      "Using cache found in /headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "Using cache found in /headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mixnet_s-a907afbc.pth\" to /headless/.cache/torch/checkpoints/mixnet_s-a907afbc.pth\n",
      "^C\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl-c pressed.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 255. Press ctrl-c to abort syncing.\n",
      "Traceback (most recent call last):\n",
      "  File \"../src/train.py\", line 382, in <module>\n",
      "    main()\n",
      "  File \"../src/train.py\", line 376, in main\n",
      "    train_loop(args)\n",
      "  File \"../src/train.py\", line 325, in train_loop\n",
      "    model, optimizer, loss = prepare_eff_model(lr=LR, device=DEVICE, name=BASE, inp_size = INP_SIZE, weight_decay=WD, beta_1=B1, beta_2=B2, im_size=IMAGE_SIZE)\n",
      "  File \"/headless/tmp/kd/src/model.py\", line 180, in prepare_eff_model\n",
      "    model =  torch.hub.load('rwightman/gen-efficientnet-pytorch', name, pretrained=True)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/hub.py\", line 359, in load\n",
      "    model = entry(*args, **kwargs)\n",
      "  File \"/headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/gen_efficientnet.py\", line 969, in mixnet_s\n",
      "    'mixnet_s', channel_multiplier=1.0, pretrained=pretrained, **kwargs)\n",
      "  File \"/headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/gen_efficientnet.py\", line 515, in _gen_mixnet_s\n",
      "    model = _create_model(model_kwargs, variant, pretrained)\n",
      "  File \"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 161556\n",
      "/headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/gen_efficientnet.py\", line 214, in _create_model\n",
      "    load_pretrained(model, model_urls[variant])\n",
      "  File \"/headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/helpers.py\", line 32, in load_pretrained\n",
      "    state_dict = load_state_dict_from_url(url, progress=False, map_location='cpu')\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/hub.py\", line 485, in load_state_dict_from_url\n",
      "    download_url_to_file(url, cached_file, hash_prefix, progress=progress)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/hub.py\", line 406, in download_url_to_file\n",
      "    buffer = u.read(8192)\n",
      "  File \"/headless/miniconda3/lib/python3.7/http/client.py\", line 457, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"/headless/miniconda3/lib/python3.7/http/client.py\", line 501, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"/headless/miniconda3/lib/python3.7/socket.py\", line 589, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/headless/miniconda3/lib/python3.7/ssl.py\", line 1071, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/headless/miniconda3/lib/python3.7/ssl.py\", line 929, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "KeyboardInterrupt\n"
>>>>>>> e58308043ccf82a4902fc482479be4e6e3beba4c
     ]
    }
   ],
   "source": [
    "!python -W ignore ../src/train.py --tags \"1#drop0.2\" --base \"mixnet_s\" --image_size 224 --wandb 1 \\\n",
<<<<<<< HEAD
    "          --batch_size 42 --inp_size 1536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -W ignore ../src/train.py --tags \"1#drop0.2\" --base \"mixnet_m\" --image_size 224 --wandb 1 \\\n",
=======
>>>>>>> e58308043ccf82a4902fc482479be4e6e3beba4c
    "          --batch_size 24 --inp_size 1536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -W ignore ../src/train.py --tags \"1#drop0.2#\" --base \"mnasnet_a1\" --image_size 224 --wandb 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
