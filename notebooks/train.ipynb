{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Using device: cuda\n",
      "True\n",
      "Tesla V100-PCIE-32GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "==> Preparing data\n",
      "==> Preparing model\n",
      "Using cache found in /headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "Using cache found in /headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "Adding attention\n",
      "==> Initialising sampler\n",
      "=====> Loading indices\n",
      "=====> Loading samples\n",
      "=====> Checking distribution\n",
      "=====> Assigning weights\n",
      "100%|███████████████████████████████████████| 2565/2565 [08:54<00:00,  4.80it/s]\n",
      "==> Training model\n",
      "  0%|                                                    | 0/36 [00:08<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"../src/train.py\", line 382, in <module>\n",
      "    main()\n",
      "  File \"../src/train.py\", line 376, in main\n",
      "    train_loop(args)\n",
      "  File \"../src/train.py\", line 338, in train_loop\n",
      "    test_len = test(model, DEVICE, test_loader, loss, epoch, num_classes=NUM_CLASSES, wandb_log=WANDB)\n",
      "  File \"../src/train.py\", line 211, in test\n",
      "    output = model(data).cuda()\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/gen_efficientnet.py\", line 207, in forward\n",
      "    return self.classifier(x)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 92, in forward\n",
      "    input = module(input)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/nn/modules/pooling.py\", line 1031, in forward\n",
      "    return F.adaptive_avg_pool2d(input, self.output_size)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/nn/functional.py\", line 768, in adaptive_avg_pool2d\n",
      "    return torch._C._nn.adaptive_avg_pool2d(input, _output_size)\n",
      "RuntimeError: shape '[36, 54, 1, 1]' is invalid for input of size 1\n",
      "Exception in thread Thread-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/headless/miniconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/headless/miniconda3/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/headless/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\", line 294, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/headless/miniconda3/lib/python3.7/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/headless/miniconda3/lib/python3.7/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/headless/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 498, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/headless/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 746, in answer_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "  File \"/headless/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/headless/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/headless/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -W ignore ../src/train.py --tags \"3#drop0.2\" --base \"efficientnet_b0\" --image_size 128 --lr 1e-3 --epochs 200 \\\n",
    "--batch_size 36 --wandb 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 6])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from attention_augmented_conv import AugmentedConv\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "                      AugmentedConv(in_channels=1280, out_channels=6, kernel_size=1, dk=40, dv=4, Nh=1, relative=False, stride=2),\n",
    "                     #nn.Conv2d(588, 6, kernel_size=1, padding = 1, stride=1, bias=False),\n",
    "                     torch.nn.BatchNorm2d(6), \n",
    "                     torch.nn.Dropout(p=0.25),\n",
    "                     torch.nn.AdaptiveAvgPool2d(1)\n",
    "                      ).to(\"cuda\")\n",
    "temp_input = torch.randn((16, 1280, 32, 32)).to('cuda')\n",
    "augmented_conv = AugmentedConv(in_channels=1280, out_channels=6, kernel_size=1, dk=40, dv=4, Nh=1, relative=False, stride=2).to('cuda')\n",
    "norm = torch.nn.BatchNorm2d(6).to(\"cuda\")\n",
    "\n",
    "conv_out = model(temp_input).squeeze()\n",
    "print(conv_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Using device: cuda\n",
      "True\n",
      "Tesla V100-PCIE-32GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "wandb!\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.8.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in ../../../shared/kern_segmentation/logs/wandb/run-20191207_222740-rqsiwlo7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m1#drop0.2_mixnet_s_ft_0.001_6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/nuvard/kern\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/nuvard/kern/runs/rqsiwlo7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "==> Preparing data\n",
      "==> Preparing model\n",
      "Using cache found in /headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "Using cache found in /headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mixnet_s-a907afbc.pth\" to /headless/.cache/torch/checkpoints/mixnet_s-a907afbc.pth\n",
      "^C\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl-c pressed.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 255. Press ctrl-c to abort syncing.\n",
      "Traceback (most recent call last):\n",
      "  File \"../src/train.py\", line 382, in <module>\n",
      "    main()\n",
      "  File \"../src/train.py\", line 376, in main\n",
      "    train_loop(args)\n",
      "  File \"../src/train.py\", line 325, in train_loop\n",
      "    model, optimizer, loss = prepare_eff_model(lr=LR, device=DEVICE, name=BASE, inp_size = INP_SIZE, weight_decay=WD, beta_1=B1, beta_2=B2, im_size=IMAGE_SIZE)\n",
      "  File \"/headless/tmp/kd/src/model.py\", line 180, in prepare_eff_model\n",
      "    model =  torch.hub.load('rwightman/gen-efficientnet-pytorch', name, pretrained=True)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/hub.py\", line 359, in load\n",
      "    model = entry(*args, **kwargs)\n",
      "  File \"/headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/gen_efficientnet.py\", line 969, in mixnet_s\n",
      "    'mixnet_s', channel_multiplier=1.0, pretrained=pretrained, **kwargs)\n",
      "  File \"/headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/gen_efficientnet.py\", line 515, in _gen_mixnet_s\n",
      "    model = _create_model(model_kwargs, variant, pretrained)\n",
      "  File \"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 161556\n",
      "/headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/gen_efficientnet.py\", line 214, in _create_model\n",
      "    load_pretrained(model, model_urls[variant])\n",
      "  File \"/headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/helpers.py\", line 32, in load_pretrained\n",
      "    state_dict = load_state_dict_from_url(url, progress=False, map_location='cpu')\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/hub.py\", line 485, in load_state_dict_from_url\n",
      "    download_url_to_file(url, cached_file, hash_prefix, progress=progress)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/hub.py\", line 406, in download_url_to_file\n",
      "    buffer = u.read(8192)\n",
      "  File \"/headless/miniconda3/lib/python3.7/http/client.py\", line 457, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"/headless/miniconda3/lib/python3.7/http/client.py\", line 501, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"/headless/miniconda3/lib/python3.7/socket.py\", line 589, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/headless/miniconda3/lib/python3.7/ssl.py\", line 1071, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/headless/miniconda3/lib/python3.7/ssl.py\", line 929, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python -W ignore ../src/train.py --tags \"1#drop0.2\" --base \"mixnet_s\" --image_size 224 --wandb 1 \\\n",
    "          --batch_size 24 --inp_size 1536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -W ignore ../src/train.py --tags \"1#drop0.2#\" --base \"mnasnet_a1\" --image_size 224 --wandb 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
