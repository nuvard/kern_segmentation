{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ttach\n",
      "  Downloading https://files.pythonhosted.org/packages/53/22/470bb42f90505dc572f6bbcf3ac84d67aaf1554cd48cc08f788c36fec129/ttach-0.0.2-py3-none-any.whl\n",
      "Installing collected packages: ttach\n",
      "Successfully installed ttach-0.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install ttach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Using device: cuda\n",
      "True\n",
      "Tesla V100-PCIE-32GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "wandb!\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.8.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in ../../shared/kern_segmentation/logs/wandb/run-20191212_171143-iap06m0v\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3#drop#att#_efficientnet_b0_ft_0.001_6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/nuvard/kern\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/nuvard/kern/runs/iap06m0v\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "==> Preparing data\n",
      "Using cache found in /headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "==> Preparing model\n",
      "Using cache found in /headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "Adding attention\n",
      "==> Initialising sampler\n",
      "=====> Loading indices\n",
      "=====> Loading samples\n",
      "=====> Checking distribution\n",
      "=====> Assigning weights\n",
      "100%|███████████████████████████████████████| 2244/2244 [07:53<00:00,  4.74it/s]\n",
      "==> Training model\n",
      "  0%|                                                   | 0/121 [00:04<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"../src/train.py\", line 402, in <module>\n",
      "    main()\n",
      "  File \"../src/train.py\", line 394, in main\n",
      "    train_loop(args)\n",
      "  File \"../src/train.py\", line 356, in train_loop\n",
      "    test_len = test(model, DEVICE, test_loader, loss, epoch, num_classes=NUM_CLASSES, wandb_log=WANDB)\n",
      "  File \"../src/train.py\", line 227, in test\n",
      "    output = tta_model(data).cuda()\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/ttach/wrappers.py\", line 83, in forward\n",
      "    augmented_output = self.model(augmented_image, *args)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\", line 150, in forward\n",
      "    return self.module(*inputs[0], **kwargs[0])\n",
      "  File \"/headless/miniconda3/lib/python3.7/si\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 217037\n",
      "te-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/gen_efficientnet.py\", line 202, in forward\n",
      "    x = self.features(x)\n",
      "  File \"/headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/gen_efficientnet.py\", line 184, in features\n",
      "    x = self.conv_stem(x)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 92, in forward\n",
      "    input = module(input)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/headless/kern_segmentation/src/attention_augmented_conv.py\", line 54, in forward\n",
      "    logits = torch.matmul(flat_q.transpose(2, 3), flat_k)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 30.60 GiB (GPU 0; 31.72 GiB total capacity; 194.81 MiB already allocated; 30.54 GiB free; 3.19 MiB cached)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1. Press ctrl-c to abort syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing 7 W&B file(s) and 0 media file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 3#drop#att#_efficientnet_b0_ft_0.001_6: https://app.wandb.ai/nuvard/kern/runs/iap06m0v\n"
     ]
    }
   ],
   "source": [
    "!python -W ignore ../src/train.py --tags \"3#drop#att#\" --base \"efficientnet_b0\" --image_size 224 --lr 1e-3 --epochs 300 \\\n",
    "--batch_size 8 --wandb 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "Using cache found in /headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 122, 122]           1,728\n",
      "       BatchNorm2d-2         [-1, 32, 122, 122]              64\n",
      "          SwishJit-3         [-1, 32, 122, 122]               0\n",
      "            Conv2d-4         [-1, 32, 122, 122]             288\n",
      "       BatchNorm2d-5         [-1, 32, 122, 122]              64\n",
      "          SwishJit-6         [-1, 32, 122, 122]               0\n",
      " AdaptiveAvgPool2d-7             [-1, 32, 1, 1]               0\n",
      "            Conv2d-8              [-1, 8, 1, 1]             264\n",
      "          SwishJit-9              [-1, 8, 1, 1]               0\n",
      "           Conv2d-10             [-1, 32, 1, 1]             288\n",
      "    SqueezeExcite-11         [-1, 32, 122, 122]               0\n",
      "           Conv2d-12         [-1, 16, 122, 122]             512\n",
      "      BatchNorm2d-13         [-1, 16, 122, 122]              32\n",
      "         Identity-14         [-1, 16, 122, 122]               0\n",
      "DepthwiseSeparableConv-15         [-1, 16, 122, 122]               0\n",
      "           Conv2d-16         [-1, 96, 122, 122]           1,536\n",
      "      BatchNorm2d-17         [-1, 96, 122, 122]             192\n",
      "         SwishJit-18         [-1, 96, 122, 122]               0\n",
      "           Conv2d-19           [-1, 96, 61, 61]             864\n",
      "      BatchNorm2d-20           [-1, 96, 61, 61]             192\n",
      "         SwishJit-21           [-1, 96, 61, 61]               0\n",
      "AdaptiveAvgPool2d-22             [-1, 96, 1, 1]               0\n",
      "           Conv2d-23              [-1, 4, 1, 1]             388\n",
      "         SwishJit-24              [-1, 4, 1, 1]               0\n",
      "           Conv2d-25             [-1, 96, 1, 1]             480\n",
      "    SqueezeExcite-26           [-1, 96, 61, 61]               0\n",
      "           Conv2d-27           [-1, 24, 61, 61]           2,304\n",
      "      BatchNorm2d-28           [-1, 24, 61, 61]              48\n",
      " InvertedResidual-29           [-1, 24, 61, 61]               0\n",
      "           Conv2d-30          [-1, 144, 61, 61]           3,456\n",
      "      BatchNorm2d-31          [-1, 144, 61, 61]             288\n",
      "         SwishJit-32          [-1, 144, 61, 61]               0\n",
      "           Conv2d-33          [-1, 144, 61, 61]           1,296\n",
      "      BatchNorm2d-34          [-1, 144, 61, 61]             288\n",
      "         SwishJit-35          [-1, 144, 61, 61]               0\n",
      "AdaptiveAvgPool2d-36            [-1, 144, 1, 1]               0\n",
      "           Conv2d-37              [-1, 6, 1, 1]             870\n",
      "         SwishJit-38              [-1, 6, 1, 1]               0\n",
      "           Conv2d-39            [-1, 144, 1, 1]           1,008\n",
      "    SqueezeExcite-40          [-1, 144, 61, 61]               0\n",
      "           Conv2d-41           [-1, 24, 61, 61]           3,456\n",
      "      BatchNorm2d-42           [-1, 24, 61, 61]              48\n",
      " InvertedResidual-43           [-1, 24, 61, 61]               0\n",
      "           Conv2d-44          [-1, 144, 61, 61]           3,456\n",
      "      BatchNorm2d-45          [-1, 144, 61, 61]             288\n",
      "         SwishJit-46          [-1, 144, 61, 61]               0\n",
      "           Conv2d-47          [-1, 144, 31, 31]           3,600\n",
      "      BatchNorm2d-48          [-1, 144, 31, 31]             288\n",
      "         SwishJit-49          [-1, 144, 31, 31]               0\n",
      "AdaptiveAvgPool2d-50            [-1, 144, 1, 1]               0\n",
      "           Conv2d-51              [-1, 6, 1, 1]             870\n",
      "         SwishJit-52              [-1, 6, 1, 1]               0\n",
      "           Conv2d-53            [-1, 144, 1, 1]           1,008\n",
      "    SqueezeExcite-54          [-1, 144, 31, 31]               0\n",
      "           Conv2d-55           [-1, 40, 31, 31]           5,760\n",
      "      BatchNorm2d-56           [-1, 40, 31, 31]              80\n",
      " InvertedResidual-57           [-1, 40, 31, 31]               0\n",
      "           Conv2d-58          [-1, 240, 31, 31]           9,600\n",
      "      BatchNorm2d-59          [-1, 240, 31, 31]             480\n",
      "         SwishJit-60          [-1, 240, 31, 31]               0\n",
      "           Conv2d-61          [-1, 240, 31, 31]           6,000\n",
      "      BatchNorm2d-62          [-1, 240, 31, 31]             480\n",
      "         SwishJit-63          [-1, 240, 31, 31]               0\n",
      "AdaptiveAvgPool2d-64            [-1, 240, 1, 1]               0\n",
      "           Conv2d-65             [-1, 10, 1, 1]           2,410\n",
      "         SwishJit-66             [-1, 10, 1, 1]               0\n",
      "           Conv2d-67            [-1, 240, 1, 1]           2,640\n",
      "    SqueezeExcite-68          [-1, 240, 31, 31]               0\n",
      "           Conv2d-69           [-1, 40, 31, 31]           9,600\n",
      "      BatchNorm2d-70           [-1, 40, 31, 31]              80\n",
      " InvertedResidual-71           [-1, 40, 31, 31]               0\n",
      "           Conv2d-72          [-1, 240, 31, 31]           9,600\n",
      "      BatchNorm2d-73          [-1, 240, 31, 31]             480\n",
      "         SwishJit-74          [-1, 240, 31, 31]               0\n",
      "           Conv2d-75          [-1, 240, 16, 16]           2,160\n",
      "      BatchNorm2d-76          [-1, 240, 16, 16]             480\n",
      "         SwishJit-77          [-1, 240, 16, 16]               0\n",
      "AdaptiveAvgPool2d-78            [-1, 240, 1, 1]               0\n",
      "           Conv2d-79             [-1, 10, 1, 1]           2,410\n",
      "         SwishJit-80             [-1, 10, 1, 1]               0\n",
      "           Conv2d-81            [-1, 240, 1, 1]           2,640\n",
      "    SqueezeExcite-82          [-1, 240, 16, 16]               0\n",
      "           Conv2d-83           [-1, 80, 16, 16]          19,200\n",
      "      BatchNorm2d-84           [-1, 80, 16, 16]             160\n",
      " InvertedResidual-85           [-1, 80, 16, 16]               0\n",
      "           Conv2d-86          [-1, 480, 16, 16]          38,400\n",
      "      BatchNorm2d-87          [-1, 480, 16, 16]             960\n",
      "         SwishJit-88          [-1, 480, 16, 16]               0\n",
      "           Conv2d-89          [-1, 480, 16, 16]           4,320\n",
      "      BatchNorm2d-90          [-1, 480, 16, 16]             960\n",
      "         SwishJit-91          [-1, 480, 16, 16]               0\n",
      "AdaptiveAvgPool2d-92            [-1, 480, 1, 1]               0\n",
      "           Conv2d-93             [-1, 20, 1, 1]           9,620\n",
      "         SwishJit-94             [-1, 20, 1, 1]               0\n",
      "           Conv2d-95            [-1, 480, 1, 1]          10,080\n",
      "    SqueezeExcite-96          [-1, 480, 16, 16]               0\n",
      "           Conv2d-97           [-1, 80, 16, 16]          38,400\n",
      "      BatchNorm2d-98           [-1, 80, 16, 16]             160\n",
      " InvertedResidual-99           [-1, 80, 16, 16]               0\n",
      "          Conv2d-100          [-1, 480, 16, 16]          38,400\n",
      "     BatchNorm2d-101          [-1, 480, 16, 16]             960\n",
      "        SwishJit-102          [-1, 480, 16, 16]               0\n",
      "          Conv2d-103          [-1, 480, 16, 16]           4,320\n",
      "     BatchNorm2d-104          [-1, 480, 16, 16]             960\n",
      "        SwishJit-105          [-1, 480, 16, 16]               0\n",
      "AdaptiveAvgPool2d-106            [-1, 480, 1, 1]               0\n",
      "          Conv2d-107             [-1, 20, 1, 1]           9,620\n",
      "        SwishJit-108             [-1, 20, 1, 1]               0\n",
      "          Conv2d-109            [-1, 480, 1, 1]          10,080\n",
      "   SqueezeExcite-110          [-1, 480, 16, 16]               0\n",
      "          Conv2d-111           [-1, 80, 16, 16]          38,400\n",
      "     BatchNorm2d-112           [-1, 80, 16, 16]             160\n",
      "InvertedResidual-113           [-1, 80, 16, 16]               0\n",
      "          Conv2d-114          [-1, 480, 16, 16]          38,400\n",
      "     BatchNorm2d-115          [-1, 480, 16, 16]             960\n",
      "        SwishJit-116          [-1, 480, 16, 16]               0\n",
      "          Conv2d-117          [-1, 480, 16, 16]          12,000\n",
      "     BatchNorm2d-118          [-1, 480, 16, 16]             960\n",
      "        SwishJit-119          [-1, 480, 16, 16]               0\n",
      "AdaptiveAvgPool2d-120            [-1, 480, 1, 1]               0\n",
      "          Conv2d-121             [-1, 20, 1, 1]           9,620\n",
      "        SwishJit-122             [-1, 20, 1, 1]               0\n",
      "          Conv2d-123            [-1, 480, 1, 1]          10,080\n",
      "   SqueezeExcite-124          [-1, 480, 16, 16]               0\n",
      "          Conv2d-125          [-1, 112, 16, 16]          53,760\n",
      "     BatchNorm2d-126          [-1, 112, 16, 16]             224\n",
      "InvertedResidual-127          [-1, 112, 16, 16]               0\n",
      "          Conv2d-128          [-1, 672, 16, 16]          75,264\n",
      "     BatchNorm2d-129          [-1, 672, 16, 16]           1,344\n",
      "        SwishJit-130          [-1, 672, 16, 16]               0\n",
      "          Conv2d-131          [-1, 672, 16, 16]          16,800\n",
      "     BatchNorm2d-132          [-1, 672, 16, 16]           1,344\n",
      "        SwishJit-133          [-1, 672, 16, 16]               0\n",
      "AdaptiveAvgPool2d-134            [-1, 672, 1, 1]               0\n",
      "          Conv2d-135             [-1, 28, 1, 1]          18,844\n",
      "        SwishJit-136             [-1, 28, 1, 1]               0\n",
      "          Conv2d-137            [-1, 672, 1, 1]          19,488\n",
      "   SqueezeExcite-138          [-1, 672, 16, 16]               0\n",
      "          Conv2d-139          [-1, 112, 16, 16]          75,264\n",
      "     BatchNorm2d-140          [-1, 112, 16, 16]             224\n",
      "InvertedResidual-141          [-1, 112, 16, 16]               0\n",
      "          Conv2d-142          [-1, 672, 16, 16]          75,264\n",
      "     BatchNorm2d-143          [-1, 672, 16, 16]           1,344\n",
      "        SwishJit-144          [-1, 672, 16, 16]               0\n",
      "          Conv2d-145          [-1, 672, 16, 16]          16,800\n",
      "     BatchNorm2d-146          [-1, 672, 16, 16]           1,344\n",
      "        SwishJit-147          [-1, 672, 16, 16]               0\n",
      "AdaptiveAvgPool2d-148            [-1, 672, 1, 1]               0\n",
      "          Conv2d-149             [-1, 28, 1, 1]          18,844\n",
      "        SwishJit-150             [-1, 28, 1, 1]               0\n",
      "          Conv2d-151            [-1, 672, 1, 1]          19,488\n",
      "   SqueezeExcite-152          [-1, 672, 16, 16]               0\n",
      "          Conv2d-153          [-1, 112, 16, 16]          75,264\n",
      "     BatchNorm2d-154          [-1, 112, 16, 16]             224\n",
      "InvertedResidual-155          [-1, 112, 16, 16]               0\n",
      "          Conv2d-156          [-1, 672, 16, 16]          75,264\n",
      "     BatchNorm2d-157          [-1, 672, 16, 16]           1,344\n",
      "        SwishJit-158          [-1, 672, 16, 16]               0\n",
      "          Conv2d-159            [-1, 672, 8, 8]          16,800\n",
      "     BatchNorm2d-160            [-1, 672, 8, 8]           1,344\n",
      "        SwishJit-161            [-1, 672, 8, 8]               0\n",
      "AdaptiveAvgPool2d-162            [-1, 672, 1, 1]               0\n",
      "          Conv2d-163             [-1, 28, 1, 1]          18,844\n",
      "        SwishJit-164             [-1, 28, 1, 1]               0\n",
      "          Conv2d-165            [-1, 672, 1, 1]          19,488\n",
      "   SqueezeExcite-166            [-1, 672, 8, 8]               0\n",
      "          Conv2d-167            [-1, 192, 8, 8]         129,024\n",
      "     BatchNorm2d-168            [-1, 192, 8, 8]             384\n",
      "InvertedResidual-169            [-1, 192, 8, 8]               0\n",
      "          Conv2d-170           [-1, 1152, 8, 8]         221,184\n",
      "     BatchNorm2d-171           [-1, 1152, 8, 8]           2,304\n",
      "        SwishJit-172           [-1, 1152, 8, 8]               0\n",
      "          Conv2d-173           [-1, 1152, 8, 8]          28,800\n",
      "     BatchNorm2d-174           [-1, 1152, 8, 8]           2,304\n",
      "        SwishJit-175           [-1, 1152, 8, 8]               0\n",
      "AdaptiveAvgPool2d-176           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-177             [-1, 48, 1, 1]          55,344\n",
      "        SwishJit-178             [-1, 48, 1, 1]               0\n",
      "          Conv2d-179           [-1, 1152, 1, 1]          56,448\n",
      "   SqueezeExcite-180           [-1, 1152, 8, 8]               0\n",
      "          Conv2d-181            [-1, 192, 8, 8]         221,184\n",
      "     BatchNorm2d-182            [-1, 192, 8, 8]             384\n",
      "InvertedResidual-183            [-1, 192, 8, 8]               0\n",
      "          Conv2d-184           [-1, 1152, 8, 8]         221,184\n",
      "     BatchNorm2d-185           [-1, 1152, 8, 8]           2,304\n",
      "        SwishJit-186           [-1, 1152, 8, 8]               0\n",
      "          Conv2d-187           [-1, 1152, 8, 8]          28,800\n",
      "     BatchNorm2d-188           [-1, 1152, 8, 8]           2,304\n",
      "        SwishJit-189           [-1, 1152, 8, 8]               0\n",
      "AdaptiveAvgPool2d-190           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-191             [-1, 48, 1, 1]          55,344\n",
      "        SwishJit-192             [-1, 48, 1, 1]               0\n",
      "          Conv2d-193           [-1, 1152, 1, 1]          56,448\n",
      "   SqueezeExcite-194           [-1, 1152, 8, 8]               0\n",
      "          Conv2d-195            [-1, 192, 8, 8]         221,184\n",
      "     BatchNorm2d-196            [-1, 192, 8, 8]             384\n",
      "InvertedResidual-197            [-1, 192, 8, 8]               0\n",
      "          Conv2d-198           [-1, 1152, 8, 8]         221,184\n",
      "     BatchNorm2d-199           [-1, 1152, 8, 8]           2,304\n",
      "        SwishJit-200           [-1, 1152, 8, 8]               0\n",
      "          Conv2d-201           [-1, 1152, 8, 8]          28,800\n",
      "     BatchNorm2d-202           [-1, 1152, 8, 8]           2,304\n",
      "        SwishJit-203           [-1, 1152, 8, 8]               0\n",
      "AdaptiveAvgPool2d-204           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-205             [-1, 48, 1, 1]          55,344\n",
      "        SwishJit-206             [-1, 48, 1, 1]               0\n",
      "          Conv2d-207           [-1, 1152, 1, 1]          56,448\n",
      "   SqueezeExcite-208           [-1, 1152, 8, 8]               0\n",
      "          Conv2d-209            [-1, 192, 8, 8]         221,184\n",
      "     BatchNorm2d-210            [-1, 192, 8, 8]             384\n",
      "InvertedResidual-211            [-1, 192, 8, 8]               0\n",
      "          Conv2d-212           [-1, 1152, 8, 8]         221,184\n",
      "     BatchNorm2d-213           [-1, 1152, 8, 8]           2,304\n",
      "        SwishJit-214           [-1, 1152, 8, 8]               0\n",
      "          Conv2d-215           [-1, 1152, 8, 8]          10,368\n",
      "     BatchNorm2d-216           [-1, 1152, 8, 8]           2,304\n",
      "        SwishJit-217           [-1, 1152, 8, 8]               0\n",
      "AdaptiveAvgPool2d-218           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-219             [-1, 48, 1, 1]          55,344\n",
      "        SwishJit-220             [-1, 48, 1, 1]               0\n",
      "          Conv2d-221           [-1, 1152, 1, 1]          56,448\n",
      "   SqueezeExcite-222           [-1, 1152, 8, 8]               0\n",
      "          Conv2d-223            [-1, 320, 8, 8]         368,640\n",
      "     BatchNorm2d-224            [-1, 320, 8, 8]             640\n",
      "InvertedResidual-225            [-1, 320, 8, 8]               0\n",
      "          Conv2d-226           [-1, 1280, 8, 8]         409,600\n",
      "     BatchNorm2d-227           [-1, 1280, 8, 8]           2,560\n",
      "        SwishJit-228           [-1, 1280, 8, 8]               0\n",
      "          Conv2d-229            [-1, 196, 4, 4]         251,076\n",
      "          Conv2d-230             [-1, 84, 4, 4]         107,604\n",
      "          Conv2d-231              [-1, 4, 4, 4]              20\n",
      "   AugmentedConv-232            [-1, 200, 4, 4]               0\n",
      "     BatchNorm2d-233            [-1, 200, 4, 4]             400\n",
      "AdaptiveAvgPool2d-234            [-1, 200, 1, 1]               0\n",
      "          Linear-235                    [-1, 6]           1,206\n",
      "================================================================\n",
      "Total params: 4,368,718\n",
      "Trainable params: 4,368,718\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.32\n",
      "Forward/backward pass size (MB): 212.87\n",
      "Params size (MB): 16.67\n",
      "Estimated Total Size (MB): 230.85\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight 32 6 3 3, but got 3-dimensional input of size [1280, 32, 32] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-4213203a3ade>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mconv_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.squeeze()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/gen_efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/gen_efficientnet.py\u001b[0m in \u001b[0;36mfeatures\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_stem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight 32 6 3 3, but got 3-dimensional input of size [1280, 32, 32] instead"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "from torchsummary import summary\n",
    "\n",
    "sys.path.append('../src/')\n",
    "from attention_augmented_conv import AugmentedConv\n",
    "torch.hub.list('rwightman/gen-efficientnet-pytorch') \n",
    "model =  torch.hub.load('rwightman/gen-efficientnet-pytorch','efficientnet_b0', pretrained=True)\n",
    "\n",
    "\n",
    "\n",
    "model.global_pool = nn.Sequential(\n",
    "                       AugmentedConv(in_channels=1280, out_channels=200, kernel_size=1, dk=40, dv=4, Nh=1, relative=False, stride=2),\n",
    "                     #nn.Conv2d(588, 6, kernel_size=1, padding = 1, stride=1, bias=False),\n",
    "                     nn.BatchNorm2d(200), \n",
    "                     #nn.Dropout(p=0.25),\n",
    "                     nn.AdaptiveAvgPool2d(1)\n",
    "                     \n",
    "                     \n",
    "                      )\n",
    "        \n",
    "model.classifier = nn.Sequential(\n",
    "           \n",
    "            #nn.BatchNorm1d(6),\n",
    "            \n",
    "                     #nn.ReLU(),\n",
    "            \n",
    "            #nn.Dropout(p=0.25),\n",
    "            #\n",
    "   #nn.BatchNorm1d(1280, eps=1e-05, momentum=0.1),\n",
    "            #nn.Dropout(p=0.5),\n",
    "            \n",
    "            #nn.ReLU(),\n",
    "            #nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Linear(200, 6),\n",
    "            #nn.AdaptiveAvgPool1d(1),\n",
    "        ) \n",
    "temp = model.conv_stem.weight\n",
    "        #model.conv_stem = AttentionConv2d(in_channels=6, out_channels=64, kernel_size=7, dk=40, dv=4, Nh=4, relative=True, stride=2, padding=3, shape = 24).to(device)\n",
    "        \n",
    "model.conv_stem = nn.Conv2d(6, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model.conv_stem.weight = nn.Parameter(torch.cat((temp,temp),dim=1))\n",
    "model.cuda()\n",
    "summary(model, (6, 240, 240))\n",
    "\n",
    "\n",
    "conv_out = model(temp_input)#.squeeze()\n",
    "print(conv_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Using device: cuda\n",
      "True\n",
      "Tesla V100-PCIE-32GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "wandb!\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.8.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in ../../../shared/kern_segmentation/logs/wandb/run-20191207_222740-rqsiwlo7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m1#drop0.2_mixnet_s_ft_0.001_6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/nuvard/kern\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/nuvard/kern/runs/rqsiwlo7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "==> Preparing data\n",
      "==> Preparing model\n",
      "Using cache found in /headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "Using cache found in /headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mixnet_s-a907afbc.pth\" to /headless/.cache/torch/checkpoints/mixnet_s-a907afbc.pth\n",
      "^C\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl-c pressed.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 255. Press ctrl-c to abort syncing.\n",
      "Traceback (most recent call last):\n",
      "  File \"../src/train.py\", line 382, in <module>\n",
      "    main()\n",
      "  File \"../src/train.py\", line 376, in main\n",
      "    train_loop(args)\n",
      "  File \"../src/train.py\", line 325, in train_loop\n",
      "    model, optimizer, loss = prepare_eff_model(lr=LR, device=DEVICE, name=BASE, inp_size = INP_SIZE, weight_decay=WD, beta_1=B1, beta_2=B2, im_size=IMAGE_SIZE)\n",
      "  File \"/headless/tmp/kd/src/model.py\", line 180, in prepare_eff_model\n",
      "    model =  torch.hub.load('rwightman/gen-efficientnet-pytorch', name, pretrained=True)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/hub.py\", line 359, in load\n",
      "    model = entry(*args, **kwargs)\n",
      "  File \"/headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/gen_efficientnet.py\", line 969, in mixnet_s\n",
      "    'mixnet_s', channel_multiplier=1.0, pretrained=pretrained, **kwargs)\n",
      "  File \"/headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/gen_efficientnet.py\", line 515, in _gen_mixnet_s\n",
      "    model = _create_model(model_kwargs, variant, pretrained)\n",
      "  File \"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 161556\n",
      "/headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/gen_efficientnet.py\", line 214, in _create_model\n",
      "    load_pretrained(model, model_urls[variant])\n",
      "  File \"/headless/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/helpers.py\", line 32, in load_pretrained\n",
      "    state_dict = load_state_dict_from_url(url, progress=False, map_location='cpu')\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/hub.py\", line 485, in load_state_dict_from_url\n",
      "    download_url_to_file(url, cached_file, hash_prefix, progress=progress)\n",
      "  File \"/headless/miniconda3/lib/python3.7/site-packages/torch/hub.py\", line 406, in download_url_to_file\n",
      "    buffer = u.read(8192)\n",
      "  File \"/headless/miniconda3/lib/python3.7/http/client.py\", line 457, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"/headless/miniconda3/lib/python3.7/http/client.py\", line 501, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"/headless/miniconda3/lib/python3.7/socket.py\", line 589, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/headless/miniconda3/lib/python3.7/ssl.py\", line 1071, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/headless/miniconda3/lib/python3.7/ssl.py\", line 929, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python -W ignore ../src/train.py --tags \"1#drop0.2\" --base \"mixnet_s\" --image_size 224 --wandb 1 \\\n",
    "          --batch_size 24 --inp_size 1536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -W ignore ../src/train.py --tags \"1#drop0.2#\" --base \"mnasnet_a1\" --image_size 224 --wandb 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
