{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ttach\n",
      "  Downloading https://files.pythonhosted.org/packages/53/22/470bb42f90505dc572f6bbcf3ac84d67aaf1554cd48cc08f788c36fec129/ttach-0.0.2-py3-none-any.whl\n",
      "Installing collected packages: ttach\n",
      "Successfully installed ttach-0.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install ttach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Not authenticated.  Copy a key from https://app.wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key: ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Using device: cuda\n",
      "True\n",
      "Tesla V100-SXM2-16GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "wandb!\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.8.16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.8.18 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in ../logs/wandb/run-20191212_210015-q3bzkomh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m5#att#_efficientnet_b0_ft_0.0002_6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/nuvard/kern\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/nuvard/kern/runs/q3bzkomh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "==> Preparing data\n",
      "==> Preparing model\n",
      "Using cache found in /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "Adding attention\n",
      "==> Initialising sampler\n",
      "=====> Loading indices\n",
      "=====> Loading samples\n",
      "=====> Checking distribution\n",
      "=====> Assigning weights\n",
      "100%|███████████████████████████████████████| 2244/2244 [05:43<00:00,  6.54it/s]\n",
      "==> Training model\n",
      "100%|█████████████████████████████████████████| 121/121 [00:42<00:00,  2.83it/s]\n",
      "Test set: Average loss: 0.2384, F1: 0.0543\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [01:14<00:00,  3.77it/s]\n",
      "[358 363 364 410 432 317]\n",
      "1\n",
      "Train Epoch: 0 \tLoss: 0.160312    F1: 0.5080    My F1: 0.5080, AP: 0.5077\n",
      "100%|█████████████████████████████████████████| 121/121 [00:43<00:00,  2.78it/s]\n",
      "Test set: Average loss: 0.1140, F1: 0.4941\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [01:12<00:00,  3.86it/s]\n",
      "[375 392 380 336 412 349]\n",
      "1\n",
      "Train Epoch: 1 \tLoss: 0.136386    F1: 0.5886    My F1: 0.5886, AP: 0.5878\n",
      "100%|█████████████████████████████████████████| 121/121 [00:42<00:00,  2.85it/s]\n",
      "Test set: Average loss: 0.1208, F1: 0.5011\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [01:12<00:00,  3.85it/s]\n",
      "[384 422 364 329 392 353]\n",
      "1\n",
      "Train Epoch: 2 \tLoss: 0.125796    F1: 0.6217    My F1: 0.6217, AP: 0.6195\n",
      "100%|█████████████████████████████████████████| 121/121 [00:43<00:00,  2.80it/s]\n",
      "Test set: Average loss: 0.0931, F1: 0.5500\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [01:13<00:00,  3.83it/s]\n",
      "[347 404 384 369 380 360]\n",
      "1\n",
      "Train Epoch: 3 \tLoss: 0.114997    F1: 0.6467    My F1: 0.6467, AP: 0.6446\n",
      "100%|█████████████████████████████████████████| 121/121 [00:42<00:00,  2.82it/s]\n",
      "Test set: Average loss: 0.1346, F1: 0.4703\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [01:13<00:00,  3.81it/s]\n",
      "[368 398 373 348 437 320]\n",
      "1\n",
      "Train Epoch: 4 \tLoss: 0.112533    F1: 0.6686    My F1: 0.6686, AP: 0.6669\n",
      "100%|█████████████████████████████████████████| 121/121 [00:43<00:00,  2.76it/s]\n",
      "Test set: Average loss: 0.1158, F1: 0.5114\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [01:13<00:00,  3.81it/s]\n",
      "[359 404 371 363 413 334]\n",
      "1\n",
      "Train Epoch: 5 \tLoss: 0.113014    F1: 0.6650    My F1: 0.6650, AP: 0.6634\n",
      "100%|█████████████████████████████████████████| 121/121 [00:43<00:00,  2.80it/s]\n",
      "Test set: Average loss: 0.0778, F1: 0.6339\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [01:14<00:00,  3.79it/s]\n",
      "[387 378 389 365 420 305]\n",
      "1\n",
      "Train Epoch: 6 \tLoss: 0.102893    F1: 0.6993    My F1: 0.6993, AP: 0.6969\n",
      "100%|█████████████████████████████████████████| 121/121 [00:43<00:00,  2.78it/s]\n",
      "Test set: Average loss: 0.0992, F1: 0.5769\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [01:16<00:00,  3.69it/s]\n",
      "[362 422 380 342 418 320]\n",
      "1\n",
      "Train Epoch: 7 \tLoss: 0.102468    F1: 0.6889    My F1: 0.6889, AP: 0.6867\n",
      "100%|█████████████████████████████████████████| 121/121 [00:47<00:00,  2.52it/s]\n",
      "Test set: Average loss: 0.0717, F1: 0.6315\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [01:24<00:00,  3.32it/s]\n",
      "[376 410 386 360 374 338]\n",
      "1\n",
      "Train Epoch: 8 \tLoss: 0.099825    F1: 0.6975    My F1: 0.6975, AP: 0.6954\n",
      "100%|█████████████████████████████████████████| 121/121 [00:48<00:00,  2.48it/s]\n",
      "Test set: Average loss: 0.0978, F1: 0.5941\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [01:23<00:00,  3.36it/s]\n",
      "[355 383 364 362 439 341]\n",
      "1\n",
      "Train Epoch: 9 \tLoss: 0.099622    F1: 0.7107    My F1: 0.7107, AP: 0.7082\n",
      "100%|█████████████████████████████████████████| 121/121 [00:48<00:00,  2.48it/s]\n",
      "Test set: Average loss: 0.0969, F1: 0.5672\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [01:23<00:00,  3.35it/s]\n",
      "[398 374 358 297 451 366]\n",
      "1\n",
      "Train Epoch: 10 \tLoss: 0.090646    F1: 0.7227    My F1: 0.7227, AP: 0.7211\n",
      "100%|█████████████████████████████████████████| 121/121 [00:48<00:00,  2.49it/s]\n",
      "Test set: Average loss: 0.0896, F1: 0.5943\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [01:19<00:00,  3.54it/s]\n",
      "[388 384 370 377 385 340]\n",
      "1\n",
      "Train Epoch: 11 \tLoss: 0.095445    F1: 0.7164    My F1: 0.7164, AP: 0.7153\n",
      "100%|█████████████████████████████████████████| 121/121 [00:46<00:00,  2.58it/s]\n",
      "Test set: Average loss: 0.0792, F1: 0.6078\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [01:21<00:00,  3.43it/s]\n",
      "[366 390 410 337 423 318]\n",
      "1\n",
      "Train Epoch: 12 \tLoss: 0.098482    F1: 0.7130    My F1: 0.7130, AP: 0.7111\n",
      "100%|█████████████████████████████████████████| 121/121 [00:48<00:00,  2.50it/s]\n",
      "Test set: Average loss: 0.0811, F1: 0.5763\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [01:22<00:00,  3.41it/s]\n",
      "[367 381 364 354 430 348]\n",
      "1\n",
      "Train Epoch: 13 \tLoss: 0.094322    F1: 0.7191    My F1: 0.7191, AP: 0.7183\n",
      "100%|█████████████████████████████████████████| 121/121 [01:22<00:00,  1.47it/s]\n",
      "Test set: Average loss: 0.1000, F1: 0.5779\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [02:26<00:00,  1.92it/s]\n",
      "[391 393 361 356 412 331]\n",
      "1\n",
      "Train Epoch: 14 \tLoss: 0.093601    F1: 0.7235    My F1: 0.7235, AP: 0.7223\n",
      "100%|█████████████████████████████████████████| 121/121 [01:33<00:00,  1.29it/s]\n",
      "Test set: Average loss: 0.0864, F1: 0.6317\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [02:15<00:00,  2.08it/s]\n",
      "[367 363 383 365 442 324]\n",
      "1\n",
      "Train Epoch: 15 \tLoss: 0.090739    F1: 0.7380    My F1: 0.7380, AP: 0.7368\n",
      "100%|█████████████████████████████████████████| 121/121 [01:31<00:00,  1.32it/s]\n",
      "Test set: Average loss: 0.0908, F1: 0.5855\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [02:17<00:00,  2.05it/s]\n",
      "[411 390 356 348 408 331]\n",
      "1\n",
      "Train Epoch: 16 \tLoss: 0.087533    F1: 0.7372    My F1: 0.7372, AP: 0.7364\n",
      "100%|█████████████████████████████████████████| 121/121 [01:27<00:00,  1.39it/s]\n",
      "Test set: Average loss: 0.0890, F1: 0.6251\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [02:26<00:00,  1.91it/s]\n",
      "[365 389 385 339 426 340]\n",
      "1\n",
      "Train Epoch: 17 \tLoss: 0.087271    F1: 0.7502    My F1: 0.7502, AP: 0.7489\n",
      "100%|█████████████████████████████████████████| 121/121 [01:22<00:00,  1.47it/s]\n",
      "Test set: Average loss: 0.0964, F1: 0.5741\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [02:29<00:00,  1.87it/s]\n",
      "[362 409 375 334 414 350]\n",
      "1\n",
      "Train Epoch: 18 \tLoss: 0.086889    F1: 0.7492    My F1: 0.7492, AP: 0.7480\n",
      "100%|█████████████████████████████████████████| 121/121 [01:21<00:00,  1.49it/s]\n",
      "Test set: Average loss: 0.0965, F1: 0.5822\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [02:15<00:00,  2.08it/s]\n",
      "[389 392 352 373 419 319]\n",
      "1\n",
      "Train Epoch: 19 \tLoss: 0.089897    F1: 0.7324    My F1: 0.7324, AP: 0.7303\n",
      "100%|█████████████████████████████████████████| 121/121 [01:33<00:00,  1.30it/s]\n",
      "Test set: Average loss: 0.0906, F1: 0.5839\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [02:19<00:00,  2.02it/s]\n",
      "[357 369 381 388 412 337]\n",
      "1\n",
      "Train Epoch: 20 \tLoss: 0.089448    F1: 0.7445    My F1: 0.7445, AP: 0.7437\n",
      "100%|█████████████████████████████████████████| 121/121 [01:30<00:00,  1.34it/s]\n",
      "Test set: Average loss: 0.1051, F1: 0.5667\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [02:15<00:00,  2.08it/s]\n",
      "[335 377 398 366 434 334]\n",
      "1\n",
      "Train Epoch: 21 \tLoss: 0.086793    F1: 0.7516    My F1: 0.7516, AP: 0.7507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 121/121 [01:30<00:00,  1.33it/s]\n",
      "Test set: Average loss: 0.0926, F1: 0.6350\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [02:21<00:00,  1.98it/s]\n",
      "[371 376 372 351 416 358]\n",
      "1\n",
      "Train Epoch: 22 \tLoss: 0.087650    F1: 0.7385    My F1: 0.7385, AP: 0.7366\n",
      "100%|█████████████████████████████████████████| 121/121 [01:19<00:00,  1.52it/s]\n",
      "Test set: Average loss: 0.0871, F1: 0.6400\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [02:30<00:00,  1.87it/s]\n",
      "[370 395 386 396 372 325]\n",
      "1\n",
      "Train Epoch: 23 \tLoss: 0.084223    F1: 0.7562    My F1: 0.7562, AP: 0.7547\n",
      "100%|█████████████████████████████████████████| 121/121 [01:12<00:00,  1.67it/s]\n",
      "Test set: Average loss: 0.0925, F1: 0.6058\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [02:20<00:00,  2.00it/s]\n",
      "[407 406 382 331 410 308]\n",
      "1\n",
      "Train Epoch: 24 \tLoss: 0.084402    F1: 0.7551    My F1: 0.7551, AP: 0.7535\n",
      "100%|█████████████████████████████████████████| 121/121 [01:27<00:00,  1.38it/s]\n",
      "Test set: Average loss: 0.0831, F1: 0.6448\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [02:04<00:00,  2.25it/s]\n",
      "[333 368 417 350 441 335]\n",
      "1\n",
      "Train Epoch: 25 \tLoss: 0.084077    F1: 0.7554    My F1: 0.7554, AP: 0.7541\n",
      "100%|█████████████████████████████████████████| 121/121 [01:34<00:00,  1.28it/s]\n",
      "Test set: Average loss: 0.0919, F1: 0.6130\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [02:07<00:00,  2.20it/s]\n",
      "[371 413 376 358 383 343]\n",
      "1\n",
      "Train Epoch: 26 \tLoss: 0.082015    F1: 0.7555    My F1: 0.7555, AP: 0.7541\n",
      "100%|█████████████████████████████████████████| 121/121 [01:35<00:00,  1.27it/s]\n",
      "Test set: Average loss: 0.0783, F1: 0.6436\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [02:16<00:00,  2.06it/s]\n",
      "[371 397 371 359 397 349]\n",
      "1\n",
      "Train Epoch: 27 \tLoss: 0.084680    F1: 0.7497    My F1: 0.7497, AP: 0.7485\n",
      "100%|█████████████████████████████████████████| 121/121 [01:36<00:00,  1.26it/s]\n",
      "Test set: Average loss: 0.1213, F1: 0.5292\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [02:33<00:00,  1.84it/s]\n",
      "[383 382 376 373 382 348]\n",
      "1\n",
      "Train Epoch: 28 \tLoss: 0.082545    F1: 0.7575    My F1: 0.7575, AP: 0.7559\n",
      "100%|█████████████████████████████████████████| 121/121 [01:31<00:00,  1.32it/s]\n",
      "Test set: Average loss: 0.0995, F1: 0.5702\n",
      "\n",
      "cuda:0\n",
      "wandb 1\n",
      "100%|█████████████████████████████████████████| 281/281 [02:45<00:00,  1.69it/s]\n",
      "[373 389 385 381 413 303]\n",
      "1\n",
      "Train Epoch: 29 \tLoss: 0.082976    F1: 0.7549    My F1: 0.7549, AP: 0.7539\n",
      " 69%|████████████████████████████▊             | 83/121 [01:01<00:38,  1.01s/it]"
     ]
    }
   ],
   "source": [
    "!python -W ignore ../src/train.py --tags \"5#att#\" --base \"efficientnet_b0\" --image_size 224 --lr 2e-4 --epochs 200 \\\n",
    "--batch_size 8 --wandb 1 --path /project/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -W ignore ../src/train.py --tags \"1#squese\" --base \"efficientnet_b2\" --image_size 260 --wandb 1 --batch_size 42 --epochs 500 --inp_size 1480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n",
      " 17%|██████▎                               | 7.44M/44.7M [00:00<00:03, 11.6MB/s]^C\n",
      " 23%|████████▊                             | 10.4M/44.7M [00:00<00:02, 15.4MB/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"../src/train.py\", line 286, in <module>\n",
      "    main()\n",
      "  File \"../src/train.py\", line 284, in main\n",
      "    train_loop(args)\n",
      "  File \"../src/train.py\", line 234, in train_loop\n",
      "    model, optimizer, loss = prepare_base_model(lr=LR, device=DEVICE, name=BASE, weight_decay=WD, beta_1=B1, beta_2=B2)\n",
      "  File \"/project/src/model.py\", line 148, in prepare_base_model\n",
      "    model = models.resnet18(pretrained=True)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\", line 231, in resnet18\n",
      "    **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\", line 217, in _resnet\n",
      "    progress=progress)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/hub.py\", line 462, in load_state_dict_from_url\n",
      "    _download_url_to_file(url, cached_file, hash_prefix, progress=progress)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/hub.py\", line 393, in _download_url_to_file\n",
      "    buffer = u.read(8192)\n",
      "  File \"/usr/lib/python3.6/http/client.py\", line 459, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"/usr/lib/python3.6/http/client.py\", line 503, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"/usr/lib/python3.6/socket.py\", line 586, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/usr/lib/python3.6/ssl.py\", line 1012, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/usr/lib/python3.6/ssl.py\", line 874, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "  File \"/usr/lib/python3.6/ssl.py\", line 631, in read\n",
      "    v = self._sslobj.read(len, buffer)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python -W ignore ../src/train.py --tags \"3#drop0.2\" --base \"resnet18\" --image_size 128 --lr 1e-3 --epochs 200 \\\n",
    "--batch_size 8 --wandb 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb!\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.8.16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.8.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in ../logs/wandb/run-20191204_091726-jsukwu9q\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m1#drop0.2_mixnet_s_ft_0.001_6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/nuvard/kern\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/nuvard/kern/runs/jsukwu9q\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "==> Preparing data\n",
      "==> Preparing model\n",
      "Downloading: \"https://github.com/rwightman/gen-efficientnet-pytorch/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n",
      "Using cache found in /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n",
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mixnet_s-a907afbc.pth\" to /root/.cache/torch/checkpoints/mixnet_s-a907afbc.pth\n",
      "GenEfficientNet(\n",
      "  (conv_stem): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): ReLU(inplace=True)\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pw): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(8, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(8, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(12, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(12, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv_dw): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "        (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(36, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(36, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "          (1): Conv2d(48, 48, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=48, bias=False)\n",
      "          (2): Conv2d(48, 48, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=48, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(144, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(12, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n",
      "          (1): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(240, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(20, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n",
      "          (1): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(240, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(20, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n",
      "          (1): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(240, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(20, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)\n",
      "          (1): Conv2d(80, 80, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=80, bias=False)\n",
      "          (2): Conv2d(80, 80, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=80, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
      "          (1): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
      "          (1): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
      "          (1): Conv2d(160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160, bias=False)\n",
      "          (2): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(480, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(40, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(240, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(240, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(60, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(60, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=90, bias=False)\n",
      "          (1): Conv2d(90, 90, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=90, bias=False)\n",
      "          (2): Conv2d(90, 90, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=90, bias=False)\n",
      "          (3): Conv2d(90, 90, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=90, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(360, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(60, 360, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(180, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(180, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(60, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(60, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=90, bias=False)\n",
      "          (1): Conv2d(90, 90, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=90, bias=False)\n",
      "          (2): Conv2d(90, 90, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=90, bias=False)\n",
      "          (3): Conv2d(90, 90, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=90, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(360, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(60, 360, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(180, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(180, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
      "          (2): Conv2d(144, 144, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=144, bias=False)\n",
      "          (3): Conv2d(144, 144, kernel_size=(9, 9), stride=(2, 2), padding=(4, 4), groups=144, bias=False)\n",
      "          (4): Conv2d(144, 144, kernel_size=(11, 11), stride=(2, 2), padding=(5, 5), groups=144, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(720, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(60, 720, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(720, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(300, 300, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=300, bias=False)\n",
      "          (1): Conv2d(300, 300, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=300, bias=False)\n",
      "          (2): Conv2d(300, 300, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=300, bias=False)\n",
      "          (3): Conv2d(300, 300, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=300, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(1200, 100, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(100, 1200, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(600, 100, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(600, 100, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(300, 300, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=300, bias=False)\n",
      "          (1): Conv2d(300, 300, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=300, bias=False)\n",
      "          (2): Conv2d(300, 300, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=300, bias=False)\n",
      "          (3): Conv2d(300, 300, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=300, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(1200, 100, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(100, 1200, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(600, 100, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(600, 100, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_head): Conv2d(200, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act2): ReLU(inplace=True)\n",
      "  (global_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Linear(in_features=1536, out_features=1000, bias=True)\n",
      ")\n",
      "GenEfficientNet(\n",
      "  (conv_stem): Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): ReLU(inplace=True)\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pw): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(8, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(8, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(12, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(12, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv_dw): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "        (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(36, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(36, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "          (1): Conv2d(48, 48, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=48, bias=False)\n",
      "          (2): Conv2d(48, 48, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=48, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(144, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(12, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n",
      "          (1): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(240, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(20, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n",
      "          (1): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(240, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(20, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(20, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n",
      "          (1): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(240, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(20, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)\n",
      "          (1): Conv2d(80, 80, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=80, bias=False)\n",
      "          (2): Conv2d(80, 80, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=80, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
      "          (1): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
      "          (1): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
      "          (1): Conv2d(160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160, bias=False)\n",
      "          (2): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(480, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(40, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(240, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(240, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(60, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(60, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=90, bias=False)\n",
      "          (1): Conv2d(90, 90, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=90, bias=False)\n",
      "          (2): Conv2d(90, 90, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=90, bias=False)\n",
      "          (3): Conv2d(90, 90, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=90, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(360, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(60, 360, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(180, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(180, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): MixedConv2d(\n",
      "          (0): Conv2d(60, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(60, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn1): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(90, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=90, bias=False)\n",
      "          (1): Conv2d(90, 90, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=90, bias=False)\n",
      "          (2): Conv2d(90, 90, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=90, bias=False)\n",
      "          (3): Conv2d(90, 90, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=90, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(360, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(60, 360, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(180, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(180, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
      "          (2): Conv2d(144, 144, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=144, bias=False)\n",
      "          (3): Conv2d(144, 144, kernel_size=(9, 9), stride=(2, 2), padding=(4, 4), groups=144, bias=False)\n",
      "          (4): Conv2d(144, 144, kernel_size=(11, 11), stride=(2, 2), padding=(5, 5), groups=144, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(720, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(60, 720, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): Conv2d(720, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(300, 300, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=300, bias=False)\n",
      "          (1): Conv2d(300, 300, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=300, bias=False)\n",
      "          (2): Conv2d(300, 300, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=300, bias=False)\n",
      "          (3): Conv2d(300, 300, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=300, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(1200, 100, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(100, 1200, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(600, 100, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(600, 100, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): SwishJit()\n",
      "        (conv_dw): MixedConv2d(\n",
      "          (0): Conv2d(300, 300, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=300, bias=False)\n",
      "          (1): Conv2d(300, 300, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=300, bias=False)\n",
      "          (2): Conv2d(300, 300, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=300, bias=False)\n",
      "          (3): Conv2d(300, 300, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=300, bias=False)\n",
      "        )\n",
      "        (bn2): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): SwishJit()\n",
      "        (se): SqueezeExcite(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv_reduce): Conv2d(1200, 100, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SwishJit()\n",
      "          (conv_expand): Conv2d(100, 1200, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (conv_pwl): MixedConv2d(\n",
      "          (0): Conv2d(600, 100, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): Conv2d(600, 100, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn3): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_head): Conv2d(200, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act2): ReLU(inplace=True)\n",
      "  (global_pool): Sequential(\n",
      "    (0): AdaptiveAvgPool2d(output_size=1)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.25, inplace=False)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=1536, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Initialising sampler\n",
      "=====> Loading indices\n",
      "=====> Loading samples\n",
      "=====> Checking distribution\n",
      "100%|███████████████████████████████████████| 2565/2565 [06:09<00:00,  6.94it/s]\n",
      "=====> Assigning weights\n",
      "100%|███████████████████████████████████████| 2565/2565 [06:05<00:00,  7.01it/s]\n",
      "==> Training model\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:29<00:00,  1.44s/it]\n",
      "1\n",
      "Train Epoch: 0 \tLoss: 0.025671    F1: 0.6131    My F1: 0.6131, AP: 0.6102\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.82s/it]\n",
      "\n",
      "Test set: Average loss: 0.0213, F1: 0.5594\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.49s/it]\n",
      "1\n",
      "Train Epoch: 1 \tLoss: 0.021836    F1: 0.6635    My F1: 0.6635, AP: 0.6632\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.73s/it]\n",
      "\n",
      "Test set: Average loss: 0.0223, F1: 0.5581\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:34<00:00,  1.53s/it]\n",
      "1\n",
      "Train Epoch: 2 \tLoss: 0.021797    F1: 0.6674    My F1: 0.6674, AP: 0.6679\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.81s/it]\n",
      "\n",
      "Test set: Average loss: 0.0237, F1: 0.5384\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:33<00:00,  1.50s/it]\n",
      "1\n",
      "Train Epoch: 3 \tLoss: 0.022260    F1: 0.6709    My F1: 0.6709, AP: 0.6709\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.78s/it]\n",
      "\n",
      "Test set: Average loss: 0.0212, F1: 0.5756\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:31<00:00,  1.47s/it]\n",
      "1\n",
      "Train Epoch: 4 \tLoss: 0.022378    F1: 0.6990    My F1: 0.6990, AP: 0.6998\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.86s/it]\n",
      "\n",
      "Test set: Average loss: 0.0209, F1: 0.5770\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.48s/it]\n",
      "1\n",
      "Train Epoch: 5 \tLoss: 0.019264    F1: 0.7080    My F1: 0.7080, AP: 0.7069\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.73s/it]\n",
      "\n",
      "Test set: Average loss: 0.0182, F1: 0.6263\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.46s/it]\n",
      "1\n",
      "Train Epoch: 6 \tLoss: 0.019247    F1: 0.7079    My F1: 0.7079, AP: 0.7085\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.83s/it]\n",
      "\n",
      "Test set: Average loss: 0.0193, F1: 0.6069\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:27<00:00,  1.41s/it]\n",
      "1\n",
      "Train Epoch: 7 \tLoss: 0.017727    F1: 0.7415    My F1: 0.7415, AP: 0.7410\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.86s/it]\n",
      "\n",
      "Test set: Average loss: 0.0182, F1: 0.6231\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:34<00:00,  1.53s/it]\n",
      "1\n",
      "Train Epoch: 8 \tLoss: 0.016615    F1: 0.7483    My F1: 0.7483, AP: 0.7481\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.75s/it]\n",
      "\n",
      "Test set: Average loss: 0.0191, F1: 0.6109\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:25<00:00,  1.38s/it]\n",
      "1\n",
      "Train Epoch: 9 \tLoss: 0.017761    F1: 0.7329    My F1: 0.7329, AP: 0.7313\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.74s/it]\n",
      "\n",
      "Test set: Average loss: 0.0168, F1: 0.6323\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.49s/it]\n",
      "1\n",
      "Train Epoch: 10 \tLoss: 0.018176    F1: 0.7308    My F1: 0.7308, AP: 0.7311\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.85s/it]\n",
      "\n",
      "Test set: Average loss: 0.0160, F1: 0.5824\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:28<00:00,  1.43s/it]\n",
      "1\n",
      "Train Epoch: 11 \tLoss: 0.016921    F1: 0.7529    My F1: 0.7529, AP: 0.7535\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.79s/it]\n",
      "\n",
      "Test set: Average loss: 0.0216, F1: 0.5769\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:25<00:00,  1.38s/it]\n",
      "1\n",
      "Train Epoch: 12 \tLoss: 0.017444    F1: 0.7529    My F1: 0.7529, AP: 0.7532\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.72s/it]\n",
      "\n",
      "Test set: Average loss: 0.0246, F1: 0.5166\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.49s/it]\n",
      "1\n",
      "Train Epoch: 13 \tLoss: 0.018597    F1: 0.7382    My F1: 0.7382, AP: 0.7382\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.77s/it]\n",
      "\n",
      "Test set: Average loss: 0.0171, F1: 0.5931\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:31<00:00,  1.47s/it]\n",
      "1\n",
      "Train Epoch: 14 \tLoss: 0.018329    F1: 0.7440    My F1: 0.7440, AP: 0.7431\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.82s/it]\n",
      "\n",
      "Test set: Average loss: 0.0160, F1: 0.6461\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.45s/it]\n",
      "1\n",
      "Train Epoch: 15 \tLoss: 0.018337    F1: 0.7255    My F1: 0.7255, AP: 0.7251\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.79s/it]\n",
      "\n",
      "Test set: Average loss: 0.0173, F1: 0.6755\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:29<00:00,  1.44s/it]\n",
      "1\n",
      "Train Epoch: 16 \tLoss: 0.018513    F1: 0.7397    My F1: 0.7397, AP: 0.7409\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.71s/it]\n",
      "\n",
      "Test set: Average loss: 0.0166, F1: 0.6066\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:28<00:00,  1.42s/it]\n",
      "1\n",
      "Train Epoch: 17 \tLoss: 0.016635    F1: 0.7517    My F1: 0.7517, AP: 0.7525\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.69s/it]\n",
      "\n",
      "Test set: Average loss: 0.0158, F1: 0.6459\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:29<00:00,  1.45s/it]\n",
      "1\n",
      "Train Epoch: 18 \tLoss: 0.015819    F1: 0.7642    My F1: 0.7642, AP: 0.7641\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.76s/it]\n",
      "\n",
      "Test set: Average loss: 0.0135, F1: 0.6672\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.49s/it]\n",
      "1\n",
      "Train Epoch: 20 \tLoss: 0.015869    F1: 0.7582    My F1: 0.7582, AP: 0.7590\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.83s/it]\n",
      "\n",
      "Test set: Average loss: 0.0134, F1: 0.6720\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:31<00:00,  1.47s/it]\n",
      "1\n",
      "Train Epoch: 21 \tLoss: 0.016921    F1: 0.7524    My F1: 0.7524, AP: 0.7525\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.70s/it]\n",
      "\n",
      "Test set: Average loss: 0.0144, F1: 0.6205\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:31<00:00,  1.47s/it]\n",
      "1\n",
      "Train Epoch: 22 \tLoss: 0.015071    F1: 0.7609    My F1: 0.7609, AP: 0.7616\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.85s/it]\n",
      "\n",
      "Test set: Average loss: 0.0143, F1: 0.6568\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.50s/it]\n",
      "1\n",
      "Train Epoch: 23 \tLoss: 0.015200    F1: 0.7739    My F1: 0.7739, AP: 0.7753\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.77s/it]\n",
      "\n",
      "Test set: Average loss: 0.0166, F1: 0.6379\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.48s/it]\n",
      "1\n",
      "Train Epoch: 24 \tLoss: 0.017259    F1: 0.7591    My F1: 0.7591, AP: 0.7600\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.76s/it]\n",
      "\n",
      "Test set: Average loss: 0.0157, F1: 0.6290\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:27<00:00,  1.41s/it]\n",
      "1\n",
      "Train Epoch: 25 \tLoss: 0.017393    F1: 0.7474    My F1: 0.7474, AP: 0.7485\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.76s/it]\n",
      "\n",
      "Test set: Average loss: 0.0183, F1: 0.6365\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:27<00:00,  1.41s/it]\n",
      "1\n",
      "Train Epoch: 26 \tLoss: 0.016669    F1: 0.7481    My F1: 0.7481, AP: 0.7473\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.81s/it]\n",
      "\n",
      "Test set: Average loss: 0.0172, F1: 0.6064\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:31<00:00,  1.47s/it]\n",
      "1\n",
      "Train Epoch: 27 \tLoss: 0.015951    F1: 0.7607    My F1: 0.7607, AP: 0.7606\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.77s/it]\n",
      "\n",
      "Test set: Average loss: 0.0168, F1: 0.6255\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.46s/it]\n",
      "1\n",
      "Train Epoch: 28 \tLoss: 0.014772    F1: 0.7767    My F1: 0.7767, AP: 0.7772\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.73s/it]\n",
      "\n",
      "Test set: Average loss: 0.0164, F1: 0.6592\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:29<00:00,  1.44s/it]\n",
      "1\n",
      "Train Epoch: 29 \tLoss: 0.016142    F1: 0.7609    My F1: 0.7609, AP: 0.7605\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.78s/it]\n",
      "\n",
      "Test set: Average loss: 0.0225, F1: 0.5733\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:26<00:00,  1.39s/it]\n",
      "1\n",
      "Train Epoch: 30 \tLoss: 0.017022    F1: 0.7484    My F1: 0.7484, AP: 0.7489\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.73s/it]\n",
      "\n",
      "Test set: Average loss: 0.0179, F1: 0.5937\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:25<00:00,  1.38s/it]\n",
      "1\n",
      "Train Epoch: 31 \tLoss: 0.018687    F1: 0.7160    My F1: 0.7160, AP: 0.7156\n",
      "100%|███████████████████████████████████████████| 16/16 [00:26<00:00,  1.67s/it]\n",
      "\n",
      "Test set: Average loss: 0.0168, F1: 0.6022\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:29<00:00,  1.44s/it]\n",
      "1\n",
      "Train Epoch: 32 \tLoss: 0.015147    F1: 0.7711    My F1: 0.7711, AP: 0.7713\n",
      "100%|███████████████████████████████████████████| 16/16 [00:26<00:00,  1.67s/it]\n",
      "\n",
      "Test set: Average loss: 0.0155, F1: 0.6895\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:27<00:00,  1.41s/it]\n",
      "1\n",
      "Train Epoch: 33 \tLoss: 0.016652    F1: 0.7440    My F1: 0.7440, AP: 0.7439\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.72s/it]\n",
      "\n",
      "Test set: Average loss: 0.0174, F1: 0.6169\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:26<00:00,  1.40s/it]\n",
      "1\n",
      "Train Epoch: 34 \tLoss: 0.014667    F1: 0.7787    My F1: 0.7787, AP: 0.7790\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.71s/it]\n",
      "\n",
      "Test set: Average loss: 0.0148, F1: 0.6561\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:23<00:00,  1.35s/it]\n",
      "1\n",
      "Train Epoch: 35 \tLoss: 0.015505    F1: 0.7602    My F1: 0.7602, AP: 0.7599\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.69s/it]\n",
      "\n",
      "Test set: Average loss: 0.0159, F1: 0.6388\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:28<00:00,  1.42s/it]\n",
      "1\n",
      "Train Epoch: 36 \tLoss: 0.017785    F1: 0.7350    My F1: 0.7350, AP: 0.7353\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.70s/it]\n",
      "\n",
      "Test set: Average loss: 0.0205, F1: 0.5887\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.47s/it]\n",
      "1\n",
      "Train Epoch: 37 \tLoss: 0.015925    F1: 0.7607    My F1: 0.7607, AP: 0.7607\n",
      "100%|███████████████████████████████████████████| 16/16 [00:26<00:00,  1.66s/it]\n",
      "\n",
      "Test set: Average loss: 0.0187, F1: 0.6118\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:28<00:00,  1.43s/it]\n",
      "1\n",
      "Train Epoch: 38 \tLoss: 0.015971    F1: 0.7704    My F1: 0.7704, AP: 0.7704\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.75s/it]\n",
      "\n",
      "Test set: Average loss: 0.0153, F1: 0.6295\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.45s/it]\n",
      "1\n",
      "Train Epoch: 39 \tLoss: 0.015928    F1: 0.7500    My F1: 0.7500, AP: 0.7492\n",
      "100%|███████████████████████████████████████████| 62/62 [01:26<00:00,  1.39s/it]\n",
      "1\n",
      "Train Epoch: 56 \tLoss: 0.016823    F1: 0.7622    My F1: 0.7622, AP: 0.7639\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.69s/it]\n",
      "\n",
      "Test set: Average loss: 0.0185, F1: 0.5960\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:26<00:00,  1.40s/it]\n",
      "1\n",
      "Train Epoch: 57 \tLoss: 0.015639    F1: 0.7752    My F1: 0.7752, AP: 0.7750\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.87s/it]\n",
      "\n",
      "Test set: Average loss: 0.0164, F1: 0.6541\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.46s/it]\n",
      "1\n",
      "Train Epoch: 58 \tLoss: 0.016165    F1: 0.7632    My F1: 0.7632, AP: 0.7622\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.78s/it]\n",
      "\n",
      "Test set: Average loss: 0.0142, F1: 0.6401\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:25<00:00,  1.38s/it]\n",
      "1\n",
      "Train Epoch: 59 \tLoss: 0.016216    F1: 0.7605    My F1: 0.7605, AP: 0.7595\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.75s/it]\n",
      "\n",
      "Test set: Average loss: 0.0193, F1: 0.6088\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:27<00:00,  1.42s/it]\n",
      "1\n",
      "Train Epoch: 60 \tLoss: 0.015052    F1: 0.7745    My F1: 0.7745, AP: 0.7757\n",
      "100%|███████████████████████████████████████████| 16/16 [00:26<00:00,  1.67s/it]\n",
      "\n",
      "Test set: Average loss: 0.0171, F1: 0.6402\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:27<00:00,  1.41s/it]\n",
      "1\n",
      "Train Epoch: 61 \tLoss: 0.016754    F1: 0.7612    My F1: 0.7612, AP: 0.7617\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.75s/it]\n",
      "\n",
      "Test set: Average loss: 0.0180, F1: 0.5912\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:29<00:00,  1.44s/it]\n",
      "1\n",
      "Train Epoch: 62 \tLoss: 0.014363    F1: 0.7926    My F1: 0.7926, AP: 0.7929\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.74s/it]\n",
      "\n",
      "Test set: Average loss: 0.0172, F1: 0.6139\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:31<00:00,  1.47s/it]\n",
      "1\n",
      "Train Epoch: 63 \tLoss: 0.015589    F1: 0.7725    My F1: 0.7725, AP: 0.7724\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.75s/it]\n",
      "\n",
      "Test set: Average loss: 0.0199, F1: 0.6231\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:31<00:00,  1.47s/it]\n",
      "1\n",
      "Train Epoch: 64 \tLoss: 0.016033    F1: 0.7630    My F1: 0.7630, AP: 0.7628\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.80s/it]\n",
      "\n",
      "Test set: Average loss: 0.0164, F1: 0.6425\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:37<00:00,  1.57s/it]\n",
      "1\n",
      "Train Epoch: 65 \tLoss: 0.015113    F1: 0.7653    My F1: 0.7653, AP: 0.7668\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.82s/it]\n",
      "\n",
      "Test set: Average loss: 0.0166, F1: 0.6048\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:37<00:00,  1.57s/it]\n",
      "1\n",
      "Train Epoch: 66 \tLoss: 0.014337    F1: 0.7736    My F1: 0.7736, AP: 0.7743\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.78s/it]\n",
      "\n",
      "Test set: Average loss: 0.0168, F1: 0.6439\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.49s/it]\n",
      "1\n",
      "Train Epoch: 67 \tLoss: 0.016832    F1: 0.7501    My F1: 0.7501, AP: 0.7502\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.82s/it]\n",
      "\n",
      "Test set: Average loss: 0.0160, F1: 0.6368\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:28<00:00,  1.43s/it]\n",
      "1\n",
      "Train Epoch: 68 \tLoss: 0.016317    F1: 0.7590    My F1: 0.7590, AP: 0.7608\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.72s/it]\n",
      "\n",
      "Test set: Average loss: 0.0182, F1: 0.5859\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:27<00:00,  1.41s/it]\n",
      "1\n",
      "Train Epoch: 69 \tLoss: 0.017624    F1: 0.7467    My F1: 0.7467, AP: 0.7462\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.69s/it]\n",
      "\n",
      "Test set: Average loss: 0.0181, F1: 0.6291\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:26<00:00,  1.40s/it]\n",
      "1\n",
      "Train Epoch: 70 \tLoss: 0.015005    F1: 0.7837    My F1: 0.7836, AP: 0.7843\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.78s/it]\n",
      "\n",
      "Test set: Average loss: 0.0155, F1: 0.6238\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:31<00:00,  1.48s/it]\n",
      "1\n",
      "Train Epoch: 71 \tLoss: 0.014342    F1: 0.7808    My F1: 0.7808, AP: 0.7803\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.76s/it]\n",
      "\n",
      "Test set: Average loss: 0.0150, F1: 0.6705\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:33<00:00,  1.51s/it]\n",
      "1\n",
      "Train Epoch: 72 \tLoss: 0.014767    F1: 0.7844    My F1: 0.7844, AP: 0.7855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.85s/it]\n",
      "\n",
      "Test set: Average loss: 0.0171, F1: 0.6092\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.46s/it]\n",
      "1\n",
      "Train Epoch: 73 \tLoss: 0.015733    F1: 0.7704    My F1: 0.7704, AP: 0.7698\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.79s/it]\n",
      "\n",
      "Test set: Average loss: 0.0176, F1: 0.5948\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.47s/it]\n",
      "1\n",
      "Train Epoch: 74 \tLoss: 0.015645    F1: 0.7610    My F1: 0.7610, AP: 0.7609\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.77s/it]\n",
      "\n",
      "Test set: Average loss: 0.0158, F1: 0.6364\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:35<00:00,  1.53s/it]\n",
      "1\n",
      "Train Epoch: 75 \tLoss: 0.014287    F1: 0.7805    My F1: 0.7805, AP: 0.7803\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.72s/it]\n",
      "\n",
      "Test set: Average loss: 0.0155, F1: 0.6887\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:27<00:00,  1.42s/it]\n",
      "1\n",
      "Train Epoch: 76 \tLoss: 0.014333    F1: 0.7885    My F1: 0.7885, AP: 0.7894\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.76s/it]\n",
      "\n",
      "Test set: Average loss: 0.0178, F1: 0.6247\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:31<00:00,  1.47s/it]\n",
      "1\n",
      "Train Epoch: 77 \tLoss: 0.016657    F1: 0.7374    My F1: 0.7374, AP: 0.7387\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.77s/it]\n",
      "\n",
      "Test set: Average loss: 0.0180, F1: 0.6089\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:28<00:00,  1.42s/it]\n",
      "1\n",
      "Train Epoch: 78 \tLoss: 0.014341    F1: 0.7851    My F1: 0.7851, AP: 0.7854\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.74s/it]\n",
      "\n",
      "Test set: Average loss: 0.0162, F1: 0.6505\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:29<00:00,  1.44s/it]\n",
      "1\n",
      "Train Epoch: 79 \tLoss: 0.016206    F1: 0.7756    My F1: 0.7756, AP: 0.7756\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.85s/it]\n",
      "\n",
      "Test set: Average loss: 0.0143, F1: 0.6276\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:26<00:00,  1.39s/it]\n",
      "1\n",
      "Train Epoch: 80 \tLoss: 0.015975    F1: 0.7611    My F1: 0.7611, AP: 0.7623\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.73s/it]\n",
      "\n",
      "Test set: Average loss: 0.0198, F1: 0.5568\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:31<00:00,  1.48s/it]\n",
      "1\n",
      "Train Epoch: 81 \tLoss: 0.015142    F1: 0.7819    My F1: 0.7819, AP: 0.7815\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.77s/it]\n",
      "\n",
      "Test set: Average loss: 0.0155, F1: 0.6183\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.49s/it]\n",
      "1\n",
      "Train Epoch: 82 \tLoss: 0.015567    F1: 0.7682    My F1: 0.7682, AP: 0.7682\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.74s/it]\n",
      "\n",
      "Test set: Average loss: 0.0173, F1: 0.6361\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.49s/it]\n",
      "1\n",
      "Train Epoch: 83 \tLoss: 0.014581    F1: 0.7752    My F1: 0.7752, AP: 0.7754\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.75s/it]\n",
      "\n",
      "Test set: Average loss: 0.0168, F1: 0.6188\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:26<00:00,  1.40s/it]\n",
      "1\n",
      "Train Epoch: 84 \tLoss: 0.014732    F1: 0.7839    My F1: 0.7839, AP: 0.7830\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.72s/it]\n",
      "\n",
      "Test set: Average loss: 0.0151, F1: 0.6596\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:35<00:00,  1.55s/it]\n",
      "1\n",
      "Train Epoch: 85 \tLoss: 0.014571    F1: 0.7969    My F1: 0.7969, AP: 0.7981\n",
      "100%|███████████████████████████████████████████| 16/16 [00:31<00:00,  1.96s/it]\n",
      "\n",
      "Test set: Average loss: 0.0146, F1: 0.6508\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:36<00:00,  1.56s/it]\n",
      "1\n",
      "Train Epoch: 86 \tLoss: 0.014614    F1: 0.7780    My F1: 0.7780, AP: 0.7774\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.74s/it]\n",
      "\n",
      "Test set: Average loss: 0.0171, F1: 0.5980\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.46s/it]\n",
      "1\n",
      "Train Epoch: 87 \tLoss: 0.015338    F1: 0.7742    My F1: 0.7742, AP: 0.7745\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.84s/it]\n",
      "\n",
      "Test set: Average loss: 0.0160, F1: 0.6319\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:34<00:00,  1.52s/it]\n",
      "1\n",
      "Train Epoch: 89 \tLoss: 0.014712    F1: 0.7828    My F1: 0.7828, AP: 0.7824\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.81s/it]\n",
      "\n",
      "Test set: Average loss: 0.0168, F1: 0.6473\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:34<00:00,  1.52s/it]\n",
      "1\n",
      "Train Epoch: 90 \tLoss: 0.014205    F1: 0.7861    My F1: 0.7861, AP: 0.7857\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.75s/it]\n",
      "\n",
      "Test set: Average loss: 0.0136, F1: 0.6674\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:34<00:00,  1.53s/it]\n",
      "1\n",
      "Train Epoch: 91 \tLoss: 0.014577    F1: 0.7831    My F1: 0.7831, AP: 0.7837\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.77s/it]\n",
      "\n",
      "Test set: Average loss: 0.0211, F1: 0.5471\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.50s/it]\n",
      "1\n",
      "Train Epoch: 92 \tLoss: 0.014182    F1: 0.7837    My F1: 0.7837, AP: 0.7820\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.78s/it]\n",
      "\n",
      "Test set: Average loss: 0.0195, F1: 0.6234\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.45s/it]\n",
      "1\n",
      "Train Epoch: 93 \tLoss: 0.013196    F1: 0.7876    My F1: 0.7876, AP: 0.7882\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.74s/it]\n",
      "\n",
      "Test set: Average loss: 0.0187, F1: 0.5945\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:26<00:00,  1.39s/it]\n",
      "1\n",
      "Train Epoch: 94 \tLoss: 0.013760    F1: 0.7978    My F1: 0.7978, AP: 0.7977\n",
      "100%|███████████████████████████████████████████| 16/16 [00:26<00:00,  1.68s/it]\n",
      "\n",
      "Test set: Average loss: 0.0175, F1: 0.6184\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:31<00:00,  1.47s/it]\n",
      "1\n",
      "Train Epoch: 95 \tLoss: 0.015158    F1: 0.7687    My F1: 0.7687, AP: 0.7688\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.72s/it]\n",
      "\n",
      "Test set: Average loss: 0.0129, F1: 0.6746\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.46s/it]\n",
      "1\n",
      "Train Epoch: 96 \tLoss: 0.014320    F1: 0.7775    My F1: 0.7775, AP: 0.7777\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.70s/it]\n",
      "\n",
      "Test set: Average loss: 0.0174, F1: 0.6162\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:31<00:00,  1.47s/it]\n",
      "1\n",
      "Train Epoch: 97 \tLoss: 0.013683    F1: 0.7977    My F1: 0.7977, AP: 0.7978\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.82s/it]\n",
      "\n",
      "Test set: Average loss: 0.0173, F1: 0.6338\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.45s/it]\n",
      "1\n",
      "Train Epoch: 98 \tLoss: 0.013506    F1: 0.7991    My F1: 0.7991, AP: 0.7999\n",
      "100%|███████████████████████████████████████████| 16/16 [00:31<00:00,  1.95s/it]\n",
      "\n",
      "Test set: Average loss: 0.0147, F1: 0.6560\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:25<00:00,  1.38s/it]\n",
      "1\n",
      "Train Epoch: 99 \tLoss: 0.014853    F1: 0.7711    My F1: 0.7711, AP: 0.7709\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.75s/it]\n",
      "\n",
      "Test set: Average loss: 0.0207, F1: 0.5563\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:28<00:00,  1.42s/it]\n",
      "1\n",
      "Train Epoch: 100 \tLoss: 0.013644    F1: 0.8000    My F1: 0.8000, AP: 0.7995\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.69s/it]\n",
      "\n",
      "Test set: Average loss: 0.0188, F1: 0.5818\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:34<00:00,  1.52s/it]\n",
      "1\n",
      "Train Epoch: 101 \tLoss: 0.014642    F1: 0.7809    My F1: 0.7809, AP: 0.7802\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.82s/it]\n",
      "\n",
      "Test set: Average loss: 0.0165, F1: 0.6330\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:33<00:00,  1.51s/it]\n",
      "1\n",
      "Train Epoch: 102 \tLoss: 0.014650    F1: 0.7978    My F1: 0.7978, AP: 0.7983\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.77s/it]\n",
      "\n",
      "Test set: Average loss: 0.0181, F1: 0.5914\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.46s/it]\n",
      "1\n",
      "Train Epoch: 103 \tLoss: 0.014342    F1: 0.7894    My F1: 0.7894, AP: 0.7899\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.72s/it]\n",
      "\n",
      "Test set: Average loss: 0.0166, F1: 0.6173\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:34<00:00,  1.52s/it]\n",
      "1\n",
      "Train Epoch: 104 \tLoss: 0.016251    F1: 0.7621    My F1: 0.7621, AP: 0.7620\n",
      "100%|███████████████████████████████████████████| 16/16 [00:30<00:00,  1.90s/it]\n",
      "\n",
      "Test set: Average loss: 0.0192, F1: 0.6203\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:33<00:00,  1.51s/it]\n",
      "1\n",
      "Train Epoch: 105 \tLoss: 0.014522    F1: 0.7760    My F1: 0.7760, AP: 0.7749\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.79s/it]\n",
      "\n",
      "Test set: Average loss: 0.0183, F1: 0.6253\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:35<00:00,  1.53s/it]\n",
      "1\n",
      "Train Epoch: 106 \tLoss: 0.013065    F1: 0.7929    My F1: 0.7929, AP: 0.7933\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.74s/it]\n",
      "\n",
      "Test set: Average loss: 0.0157, F1: 0.6418\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:33<00:00,  1.50s/it]\n",
      "1\n",
      "Train Epoch: 107 \tLoss: 0.014746    F1: 0.7809    My F1: 0.7809, AP: 0.7822\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.77s/it]\n",
      "\n",
      "Test set: Average loss: 0.0186, F1: 0.6366\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.46s/it]\n",
      "1\n",
      "Train Epoch: 108 \tLoss: 0.014308    F1: 0.7792    My F1: 0.7792, AP: 0.7794\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.78s/it]\n",
      "\n",
      "Test set: Average loss: 0.0159, F1: 0.6142\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:35<00:00,  1.54s/it]\n",
      "1\n",
      "Train Epoch: 109 \tLoss: 0.013666    F1: 0.7912    My F1: 0.7912, AP: 0.7908\n",
      "100%|███████████████████████████████████████████| 16/16 [00:32<00:00,  2.04s/it]\n",
      "\n",
      "Test set: Average loss: 0.0174, F1: 0.6358\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.46s/it]\n",
      "1\n",
      "Train Epoch: 110 \tLoss: 0.013590    F1: 0.7958    My F1: 0.7958, AP: 0.7956\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.70s/it]\n",
      "\n",
      "Test set: Average loss: 0.0137, F1: 0.6877\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:28<00:00,  1.43s/it]\n",
      "1\n",
      "Train Epoch: 111 \tLoss: 0.014000    F1: 0.7965    My F1: 0.7965, AP: 0.7962\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.69s/it]\n",
      "\n",
      "Test set: Average loss: 0.0179, F1: 0.6074\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:33<00:00,  1.51s/it]\n",
      "1\n",
      "Train Epoch: 112 \tLoss: 0.014191    F1: 0.8073    My F1: 0.8073, AP: 0.8066\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.71s/it]\n",
      "\n",
      "Test set: Average loss: 0.0156, F1: 0.6384\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:28<00:00,  1.43s/it]\n",
      "1\n",
      "Train Epoch: 113 \tLoss: 0.014006    F1: 0.7893    My F1: 0.7893, AP: 0.7899\n",
      "100%|███████████████████████████████████████████| 16/16 [00:30<00:00,  1.89s/it]\n",
      "\n",
      "Test set: Average loss: 0.0183, F1: 0.6235\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:29<00:00,  1.44s/it]\n",
      "1\n",
      "Train Epoch: 114 \tLoss: 0.014458    F1: 0.7910    My F1: 0.7910, AP: 0.7900\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.82s/it]\n",
      "\n",
      "Test set: Average loss: 0.0163, F1: 0.6175\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:29<00:00,  1.44s/it]\n",
      "1\n",
      "Train Epoch: 115 \tLoss: 0.014509    F1: 0.7854    My F1: 0.7854, AP: 0.7849\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.80s/it]\n",
      "\n",
      "Test set: Average loss: 0.0161, F1: 0.6351\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.46s/it]\n",
      "1\n",
      "Train Epoch: 116 \tLoss: 0.013885    F1: 0.7970    My F1: 0.7970, AP: 0.7970\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.73s/it]\n",
      "\n",
      "Test set: Average loss: 0.0148, F1: 0.6467\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:29<00:00,  1.44s/it]\n",
      "1\n",
      "Train Epoch: 117 \tLoss: 0.014728    F1: 0.7858    My F1: 0.7858, AP: 0.7864\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.82s/it]\n",
      "\n",
      "Test set: Average loss: 0.0151, F1: 0.6639\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:35<00:00,  1.54s/it]\n",
      "1\n",
      "Train Epoch: 118 \tLoss: 0.013339    F1: 0.8034    My F1: 0.8034, AP: 0.8045\n",
      "100%|███████████████████████████████████████████| 16/16 [00:29<00:00,  1.83s/it]\n",
      "\n",
      "Test set: Average loss: 0.0157, F1: 0.6683\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.46s/it]\n",
      "1\n",
      "Train Epoch: 119 \tLoss: 0.014361    F1: 0.7884    My F1: 0.7884, AP: 0.7899\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.76s/it]\n",
      "\n",
      "Test set: Average loss: 0.0169, F1: 0.6151\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.49s/it]\n",
      "1\n",
      "Train Epoch: 120 \tLoss: 0.014863    F1: 0.7721    My F1: 0.7721, AP: 0.7717\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.73s/it]\n",
      "\n",
      "Test set: Average loss: 0.0227, F1: 0.5804\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:27<00:00,  1.42s/it]\n",
      "1\n",
      "Train Epoch: 121 \tLoss: 0.014332    F1: 0.7908    My F1: 0.7908, AP: 0.7904\n",
      "100%|███████████████████████████████████████████| 16/16 [00:28<00:00,  1.77s/it]\n",
      "\n",
      "Test set: Average loss: 0.0159, F1: 0.6135\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:29<00:00,  1.45s/it]\n",
      "1\n",
      "Train Epoch: 122 \tLoss: 0.016058    F1: 0.7624    My F1: 0.7624, AP: 0.7619\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.69s/it]\n",
      "\n",
      "Test set: Average loss: 0.0175, F1: 0.6298\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:32<00:00,  1.50s/it]\n",
      "1\n",
      "Train Epoch: 123 \tLoss: 0.014907    F1: 0.7776    My F1: 0.7776, AP: 0.7768\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.72s/it]\n",
      "\n",
      "Test set: Average loss: 0.0173, F1: 0.6374\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:30<00:00,  1.45s/it]\n",
      "1\n",
      "Train Epoch: 124 \tLoss: 0.013922    F1: 0.7955    My F1: 0.7955, AP: 0.7957\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.72s/it]\n",
      "\n",
      "Test set: Average loss: 0.0135, F1: 0.7004\n",
      "\n",
      "wandb 1\n",
      "100%|███████████████████████████████████████████| 62/62 [01:27<00:00,  1.41s/it]\n",
      "1\n",
      "Train Epoch: 125 \tLoss: 0.014071    F1: 0.7872    My F1: 0.7872, AP: 0.7866\n",
      "100%|███████████████████████████████████████████| 16/16 [00:27<00:00,  1.75s/it]\n",
      "\n",
      "Test set: Average loss: 0.0159, F1: 0.6270\n",
      "\n",
      "wandb 1\n",
      " 19%|████████▎                                  | 12/62 [00:19<00:53,  1.06s/it]"
     ]
    }
   ],
   "source": [
    "!python -W ignore ../src/train.py --tags \"1#drop0.2\" --base \"mixnet_s\" --image_size 224 --wandb 1 \\\n",
    "          --batch_size 42 --inp_size 1536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -W ignore ../src/train.py --tags \"1#drop0.2\" --base \"mixnet_m\" --image_size 224 --wandb 1 \\\n",
    "          --batch_size 24 --inp_size 1536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -W ignore ../src/train.py --tags \"1#drop0.2#\" --base \"mnasnet_a1\" --image_size 224 --wandb 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
